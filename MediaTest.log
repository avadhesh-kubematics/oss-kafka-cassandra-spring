WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$1 (file:/usr/share/maven/lib/guice.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$1
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
[[1;34mINFO[m] Scanning for projects...
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1mBuilding oss-kafka-cassandra-spring 0.0.1-SNAPSHOT[m
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:3.1.0:resources[m [1m(default-resources)[m @ [36moss-kafka-cassandra-spring[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 2 resources
[[1;34mINFO[m] Copying 4 resources
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:compile[m [1m(default-compile)[m @ [36moss-kafka-cassandra-spring[0;1m ---[m
[[1;34mINFO[m] Changes detected - recompiling the module!
[[1;34mINFO[m] Compiling 9 source files to /media/sf_PNY480/javacode/oss-kafka-cassandra-spring/target/classes
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-resources-plugin:3.1.0:testResources[m [1m(default-testResources)[m @ [36moss-kafka-cassandra-spring[0;1m ---[m
[[1;34mINFO[m] Using 'UTF-8' encoding to copy filtered resources.
[[1;34mINFO[m] Copying 1 resource
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-compiler-plugin:3.8.1:testCompile[m [1m(default-testCompile)[m @ [36moss-kafka-cassandra-spring[0;1m ---[m
[[1;34mINFO[m] Changes detected - recompiling the module!
[[1;34mINFO[m] Compiling 3 source files to /media/sf_PNY480/javacode/oss-kafka-cassandra-spring/target/test-classes
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mmaven-surefire-plugin:2.22.2:test[m [1m(default-test)[m @ [36moss-kafka-cassandra-spring[0;1m ---[m
[[1;34mINFO[m] 
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m]  T E S T S
[[1;34mINFO[m] -------------------------------------------------------
[[1;34mINFO[m] Running com.shoreviewanalytics.osskafkacassandraspring.tests.[1mMediaTest[m
09:03:00.786 [main] DEBUG org.springframework.test.context.junit4.SpringJUnit4ClassRunner - SpringJUnit4ClassRunner constructor called with [class com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest]
09:03:00.815 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating CacheAwareContextLoaderDelegate from class [org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate]
09:03:00.832 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating BootstrapContext using constructor [public org.springframework.test.context.support.DefaultBootstrapContext(java.lang.Class,org.springframework.test.context.CacheAwareContextLoaderDelegate)]
09:03:00.868 [main] DEBUG org.springframework.test.context.BootstrapUtils - Instantiating TestContextBootstrapper for test class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest] from class [org.springframework.boot.test.context.SpringBootTestContextBootstrapper]
09:03:00.890 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Neither @ContextConfiguration nor @ContextHierarchy found for test class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest], using SpringBootContextLoader
09:03:00.902 [main] DEBUG org.springframework.test.context.support.AbstractContextLoader - Did not detect default resource location for test class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest]: class path resource [com/shoreviewanalytics/osskafkacassandraspring/tests/MediaTest-context.xml] does not exist
09:03:00.906 [main] DEBUG org.springframework.test.context.support.AbstractContextLoader - Did not detect default resource location for test class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest]: class path resource [com/shoreviewanalytics/osskafkacassandraspring/tests/MediaTestContext.groovy] does not exist
09:03:00.906 [main] INFO org.springframework.test.context.support.AbstractContextLoader - Could not detect default resource locations for test class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest]: no resource found for suffixes {-context.xml, Context.groovy}.
09:03:00.909 [main] INFO org.springframework.test.context.support.AnnotationConfigContextLoaderUtils - Could not detect default configuration classes for test class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest]: MediaTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
09:03:01.021 [main] DEBUG org.springframework.test.context.support.ActiveProfilesUtils - Could not find an 'annotation declaring class' for annotation type [org.springframework.test.context.ActiveProfiles] and class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest]
09:03:01.400 [main] DEBUG org.springframework.context.annotation.ClassPathScanningCandidateComponentProvider - Identified candidate component class: file [/media/sf_PNY480/javacode/oss-kafka-cassandra-spring/target/classes/com/shoreviewanalytics/OssKafkaCassandraSpringApplication.class]
09:03:01.407 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Found @SpringBootConfiguration com.shoreviewanalytics.OssKafkaCassandraSpringApplication for test class com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest
09:03:01.706 [main] DEBUG org.springframework.boot.test.context.SpringBootTestContextBootstrapper - @TestExecutionListeners is not present for class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest]: using defaults.
09:03:01.708 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
09:03:01.749 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper - Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@3406472c, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@5717c37, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@68f4865, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@4816278d, org.springframework.test.context.support.DirtiesContextTestExecutionListener@4eaf3684, org.springframework.test.context.transaction.TransactionalTestExecutionListener@40317ba2, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@3c01cfa1, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@45d2ade3, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@727eb8cb, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@39d9314d, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@b978d10, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@5b7a8434]
09:03:01.753 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest]
09:03:01.754 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest]
09:03:01.758 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest]
09:03:01.758 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest]
09:03:01.760 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest]
09:03:01.761 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest]
09:03:01.772 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest]
09:03:01.772 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest]
09:03:02.129 [main] INFO kafka.utils.Log4jControllerRegistration$ - Registered kafka:type=kafka.Log4jController MBean
09:03:02.404 [main] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
09:03:02.405 [main] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:host.name=bobber
09:03:02.405 [main] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:java.version=11.0.1
09:03:02.406 [main] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:java.vendor=Oracle Corporation
09:03:02.406 [main] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:java.home=/usr/lib/jvm/jdk-11.0.1
09:03:02.406 [main] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:java.class.path=/media/sf_PNY480/javacode/oss-kafka-cassandra-spring/target/test-classes:/media/sf_PNY480/javacode/oss-kafka-cassandra-spring/target/classes:/home/one/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.9.RELEASE/spring-boot-starter-2.1.9.RELEASE.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot/2.1.9.RELEASE/spring-boot-2.1.9.RELEASE.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.9.RELEASE/spring-boot-autoconfigure-2.1.9.RELEASE.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot-starter-logging/2.1.9.RELEASE/spring-boot-starter-logging-2.1.9.RELEASE.jar:/home/one/.m2/repository/ch/qos/logback/logback-classic/1.2.3/logback-classic-1.2.3.jar:/home/one/.m2/repository/ch/qos/logback/logback-core/1.2.3/logback-core-1.2.3.jar:/home/one/.m2/repository/org/apache/logging/log4j/log4j-to-slf4j/2.11.2/log4j-to-slf4j-2.11.2.jar:/home/one/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar:/home/one/.m2/repository/org/slf4j/jul-to-slf4j/1.7.28/jul-to-slf4j-1.7.28.jar:/home/one/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/one/.m2/repository/org/springframework/spring-core/5.1.10.RELEASE/spring-core-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/springframework/spring-jcl/5.1.10.RELEASE/spring-jcl-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/yaml/snakeyaml/1.23/snakeyaml-1.23.jar:/home/one/.m2/repository/org/springframework/kafka/spring-kafka/2.2.9.RELEASE/spring-kafka-2.2.9.RELEASE.jar:/home/one/.m2/repository/org/springframework/spring-context/5.1.10.RELEASE/spring-context-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/springframework/spring-aop/5.1.10.RELEASE/spring-aop-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/springframework/spring-beans/5.1.10.RELEASE/spring-beans-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/springframework/spring-expression/5.1.10.RELEASE/spring-expression-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/springframework/spring-messaging/5.1.10.RELEASE/spring-messaging-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/springframework/spring-tx/5.1.10.RELEASE/spring-tx-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/springframework/retry/spring-retry/1.2.4.RELEASE/spring-retry-1.2.4.RELEASE.jar:/home/one/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1.jar:/home/one/.m2/repository/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/home/one/.m2/repository/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot-starter-test/2.1.9.RELEASE/spring-boot-starter-test-2.1.9.RELEASE.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot-test/2.1.9.RELEASE/spring-boot-test-2.1.9.RELEASE.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/2.1.9.RELEASE/spring-boot-test-autoconfigure-2.1.9.RELEASE.jar:/home/one/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/one/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/one/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/one/.m2/repository/junit/junit/4.12/junit-4.12.jar:/home/one/.m2/repository/org/assertj/assertj-core/3.11.1/assertj-core-3.11.1.jar:/home/one/.m2/repository/org/mockito/mockito-core/2.23.4/mockito-core-2.23.4.jar:/home/one/.m2/repository/net/bytebuddy/byte-buddy/1.9.16/byte-buddy-1.9.16.jar:/home/one/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.16/byte-buddy-agent-1.9.16.jar:/home/one/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/one/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/one/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/home/one/.m2/repository/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/home/one/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/home/one/.m2/repository/org/springframework/spring-test/5.1.10.RELEASE/spring-test-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/xmlunit/xmlunit-core/2.6.3/xmlunit-core-2.6.3.jar:/home/one/.m2/repository/javax/xml/bind/jaxb-api/2.3.1/jaxb-api-2.3.1.jar:/home/one/.m2/repository/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/home/one/.m2/repository/org/springframework/kafka/spring-kafka-test/2.2.9.RELEASE/spring-kafka-test-2.2.9.RELEASE.jar:/home/one/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1-test.jar:/home/one/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1.jar:/home/one/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.9.3/jackson-databind-2.9.9.3.jar:/home/one/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/home/one/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.9/jackson-core-2.9.9.jar:/home/one/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/home/one/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/one/.m2/repository/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/home/one/.m2/repository/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/home/one/.m2/repository/com/typesafe/scala-logging/scala-logging_2.11/3.9.0/scala-logging_2.11-3.9.0.jar:/home/one/.m2/repository/com/101tec/zkclient/0.10/zkclient-0.10.jar:/home/one/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/one/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/one/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1-test.jar:/home/one/.m2/repository/org/apache/commons/commons-csv/1.7/commons-csv-1.7.jar:/home/one/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot-starter-web/2.1.9.RELEASE/spring-boot-starter-web-2.1.9.RELEASE.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot-starter-json/2.1.9.RELEASE/spring-boot-starter-json-2.1.9.RELEASE.jar:/home/one/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.9/jackson-datatype-jdk8-2.9.9.jar:/home/one/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.9/jackson-datatype-jsr310-2.9.9.jar:/home/one/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.9/jackson-module-parameter-names-2.9.9.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/2.1.9.RELEASE/spring-boot-starter-tomcat-2.1.9.RELEASE.jar:/home/one/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/9.0.26/tomcat-embed-core-9.0.26.jar:/home/one/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/9.0.26/tomcat-embed-el-9.0.26.jar:/home/one/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.26/tomcat-embed-websocket-9.0.26.jar:/home/one/.m2/repository/org/hibernate/validator/hibernate-validator/6.0.17.Final/hibernate-validator-6.0.17.Final.jar:/home/one/.m2/repository/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/home/one/.m2/repository/org/jboss/logging/jboss-logging/3.3.3.Final/jboss-logging-3.3.3.Final.jar:/home/one/.m2/repository/com/fasterxml/classmate/1.4.0/classmate-1.4.0.jar:/home/one/.m2/repository/org/springframework/spring-web/5.1.10.RELEASE/spring-web-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/springframework/spring-webmvc/5.1.10.RELEASE/spring-webmvc-5.1.10.RELEASE.jar:/home/one/.m2/repository/com/datastax/oss/java-driver-core/4.2.1/java-driver-core-4.2.1.jar:/home/one/.m2/repository/com/datastax/oss/native-protocol/1.4.6/native-protocol-1.4.6.jar:/home/one/.m2/repository/io/netty/netty-handler/4.1.39.Final/netty-handler-4.1.39.Final.jar:/home/one/.m2/repository/io/netty/netty-common/4.1.39.Final/netty-common-4.1.39.Final.jar:/home/one/.m2/repository/io/netty/netty-buffer/4.1.39.Final/netty-buffer-4.1.39.Final.jar:/home/one/.m2/repository/io/netty/netty-transport/4.1.39.Final/netty-transport-4.1.39.Final.jar:/home/one/.m2/repository/io/netty/netty-resolver/4.1.39.Final/netty-resolver-4.1.39.Final.jar:/home/one/.m2/repository/io/netty/netty-codec/4.1.39.Final/netty-codec-4.1.39.Final.jar:/home/one/.m2/repository/com/datastax/oss/java-driver-shaded-guava/25.1-jre/java-driver-shaded-guava-25.1-jre.jar:/home/one/.m2/repository/com/typesafe/config/1.3.4/config-1.3.4.jar:/home/one/.m2/repository/com/github/jnr/jnr-ffi/2.1.10/jnr-ffi-2.1.10.jar:/home/one/.m2/repository/com/github/jnr/jffi/1.2.19/jffi-1.2.19.jar:/home/one/.m2/repository/com/github/jnr/jffi/1.2.19/jffi-1.2.19-native.jar:/home/one/.m2/repository/org/ow2/asm/asm/7.1/asm-7.1.jar:/home/one/.m2/repository/org/ow2/asm/asm-commons/7.1/asm-commons-7.1.jar:/home/one/.m2/repository/org/ow2/asm/asm-analysis/7.1/asm-analysis-7.1.jar:/home/one/.m2/repository/org/ow2/asm/asm-tree/7.1/asm-tree-7.1.jar:/home/one/.m2/repository/org/ow2/asm/asm-util/7.1/asm-util-7.1.jar:/home/one/.m2/repository/com/github/jnr/jnr-a64asm/1.0.0/jnr-a64asm-1.0.0.jar:/home/one/.m2/repository/com/github/jnr/jnr-x86asm/1.0.2/jnr-x86asm-1.0.2.jar:/home/one/.m2/repository/com/github/jnr/jnr-posix/3.0.50/jnr-posix-3.0.50.jar:/home/one/.m2/repository/com/github/jnr/jnr-constants/0.9.12/jnr-constants-0.9.12.jar:/home/one/.m2/repository/org/slf4j/slf4j-api/1.7.28/slf4j-api-1.7.28.jar:/home/one/.m2/repository/io/dropwizard/metrics/metrics-core/4.0.6/metrics-core-4.0.6.jar:/home/one/.m2/repository/org/hdrhistogram/HdrHistogram/2.1.11/HdrHistogram-2.1.11.jar:/home/one/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/one/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/one/.m2/repository/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/home/one/.m2/repository/com/datastax/oss/java-driver-query-builder/4.2.1/java-driver-query-builder-4.2.1.jar:/home/one/.m2/repository/com/datastax/cassandra/cassandra-driver-core/3.6.0/cassandra-driver-core-3.6.0.jar:/home/one/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:
09:03:02.407 [main] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib
09:03:02.407 [main] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:java.io.tmpdir=/tmp
09:03:02.407 [main] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:java.compiler=<NA>
09:03:02.407 [main] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:os.name=Linux
09:03:02.407 [main] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:os.arch=amd64
09:03:02.407 [main] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:os.version=4.15.0-65-generic
09:03:02.407 [main] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:user.name=one
09:03:02.407 [main] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:user.home=/home/one
09:03:02.407 [main] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:user.dir=/media/sf_PNY480/javacode/oss-kafka-cassandra-spring
09:03:02.417 [main] DEBUG org.apache.zookeeper.server.persistence.FileTxnSnapLog - Opening datadir:/tmp/kafka-12056317453076009020 snapDir:/tmp/kafka-1695328387772169824
09:03:02.439 [main] INFO org.apache.zookeeper.server.ZooKeeperServer - Created server with tickTime 500 minSessionTimeout 1000 maxSessionTimeout 10000 datadir /tmp/kafka-12056317453076009020/version-2 snapdir /tmp/kafka-1695328387772169824/version-2
09:03:02.455 [main] INFO org.apache.zookeeper.server.NIOServerCnxnFactory - binding to port /127.0.0.1:0
09:03:02.512 [main] DEBUG org.apache.zookeeper.server.ZooKeeperServer - ZKShutdownHandler is not registered, so ZooKeeper server won't take any action on ERROR or SHUTDOWN server state changes
09:03:02.528 [main] DEBUG org.I0Itec.zkclient.ZkConnection - Creating new ZookKeeper instance to connect to 127.0.0.1:36547.
09:03:02.528 [ZkClient-EventThread-20-127.0.0.1:36547] INFO org.I0Itec.zkclient.ZkEventThread - Starting ZkClient event thread.
09:03:02.537 [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
09:03:02.537 [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:host.name=bobber
09:03:02.537 [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.version=11.0.1
09:03:02.537 [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
09:03:02.537 [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/jdk-11.0.1
09:03:02.537 [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/media/sf_PNY480/javacode/oss-kafka-cassandra-spring/target/test-classes:/media/sf_PNY480/javacode/oss-kafka-cassandra-spring/target/classes:/home/one/.m2/repository/org/springframework/boot/spring-boot-starter/2.1.9.RELEASE/spring-boot-starter-2.1.9.RELEASE.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot/2.1.9.RELEASE/spring-boot-2.1.9.RELEASE.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot-autoconfigure/2.1.9.RELEASE/spring-boot-autoconfigure-2.1.9.RELEASE.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot-starter-logging/2.1.9.RELEASE/spring-boot-starter-logging-2.1.9.RELEASE.jar:/home/one/.m2/repository/ch/qos/logback/logback-classic/1.2.3/logback-classic-1.2.3.jar:/home/one/.m2/repository/ch/qos/logback/logback-core/1.2.3/logback-core-1.2.3.jar:/home/one/.m2/repository/org/apache/logging/log4j/log4j-to-slf4j/2.11.2/log4j-to-slf4j-2.11.2.jar:/home/one/.m2/repository/org/apache/logging/log4j/log4j-api/2.11.2/log4j-api-2.11.2.jar:/home/one/.m2/repository/org/slf4j/jul-to-slf4j/1.7.28/jul-to-slf4j-1.7.28.jar:/home/one/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/one/.m2/repository/org/springframework/spring-core/5.1.10.RELEASE/spring-core-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/springframework/spring-jcl/5.1.10.RELEASE/spring-jcl-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/yaml/snakeyaml/1.23/snakeyaml-1.23.jar:/home/one/.m2/repository/org/springframework/kafka/spring-kafka/2.2.9.RELEASE/spring-kafka-2.2.9.RELEASE.jar:/home/one/.m2/repository/org/springframework/spring-context/5.1.10.RELEASE/spring-context-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/springframework/spring-aop/5.1.10.RELEASE/spring-aop-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/springframework/spring-beans/5.1.10.RELEASE/spring-beans-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/springframework/spring-expression/5.1.10.RELEASE/spring-expression-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/springframework/spring-messaging/5.1.10.RELEASE/spring-messaging-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/springframework/spring-tx/5.1.10.RELEASE/spring-tx-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/springframework/retry/spring-retry/1.2.4.RELEASE/spring-retry-1.2.4.RELEASE.jar:/home/one/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1.jar:/home/one/.m2/repository/org/lz4/lz4-java/1.4.1/lz4-java-1.4.1.jar:/home/one/.m2/repository/org/xerial/snappy/snappy-java/1.1.7.1/snappy-java-1.1.7.1.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot-starter-test/2.1.9.RELEASE/spring-boot-starter-test-2.1.9.RELEASE.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot-test/2.1.9.RELEASE/spring-boot-test-2.1.9.RELEASE.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot-test-autoconfigure/2.1.9.RELEASE/spring-boot-test-autoconfigure-2.1.9.RELEASE.jar:/home/one/.m2/repository/com/jayway/jsonpath/json-path/2.4.0/json-path-2.4.0.jar:/home/one/.m2/repository/net/minidev/json-smart/2.3/json-smart-2.3.jar:/home/one/.m2/repository/net/minidev/accessors-smart/1.2/accessors-smart-1.2.jar:/home/one/.m2/repository/junit/junit/4.12/junit-4.12.jar:/home/one/.m2/repository/org/assertj/assertj-core/3.11.1/assertj-core-3.11.1.jar:/home/one/.m2/repository/org/mockito/mockito-core/2.23.4/mockito-core-2.23.4.jar:/home/one/.m2/repository/net/bytebuddy/byte-buddy/1.9.16/byte-buddy-1.9.16.jar:/home/one/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.16/byte-buddy-agent-1.9.16.jar:/home/one/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar:/home/one/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/one/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/home/one/.m2/repository/org/skyscreamer/jsonassert/1.5.0/jsonassert-1.5.0.jar:/home/one/.m2/repository/com/vaadin/external/google/android-json/0.0.20131108.vaadin1/android-json-0.0.20131108.vaadin1.jar:/home/one/.m2/repository/org/springframework/spring-test/5.1.10.RELEASE/spring-test-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/xmlunit/xmlunit-core/2.6.3/xmlunit-core-2.6.3.jar:/home/one/.m2/repository/javax/xml/bind/jaxb-api/2.3.1/jaxb-api-2.3.1.jar:/home/one/.m2/repository/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/home/one/.m2/repository/org/springframework/kafka/spring-kafka-test/2.2.9.RELEASE/spring-kafka-test-2.2.9.RELEASE.jar:/home/one/.m2/repository/org/apache/kafka/kafka-clients/2.0.1/kafka-clients-2.0.1-test.jar:/home/one/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1.jar:/home/one/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.9.3/jackson-databind-2.9.9.3.jar:/home/one/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.0/jackson-annotations-2.9.0.jar:/home/one/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.9/jackson-core-2.9.9.jar:/home/one/.m2/repository/net/sf/jopt-simple/jopt-simple/5.0.4/jopt-simple-5.0.4.jar:/home/one/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/one/.m2/repository/org/scala-lang/scala-library/2.11.12/scala-library-2.11.12.jar:/home/one/.m2/repository/org/scala-lang/scala-reflect/2.11.12/scala-reflect-2.11.12.jar:/home/one/.m2/repository/com/typesafe/scala-logging/scala-logging_2.11/3.9.0/scala-logging_2.11-3.9.0.jar:/home/one/.m2/repository/com/101tec/zkclient/0.10/zkclient-0.10.jar:/home/one/.m2/repository/org/apache/zookeeper/zookeeper/3.4.13/zookeeper-3.4.13.jar:/home/one/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/one/.m2/repository/org/apache/kafka/kafka_2.11/2.0.1/kafka_2.11-2.0.1-test.jar:/home/one/.m2/repository/org/apache/commons/commons-csv/1.7/commons-csv-1.7.jar:/home/one/.m2/repository/org/apache/commons/commons-lang3/3.9/commons-lang3-3.9.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot-starter-web/2.1.9.RELEASE/spring-boot-starter-web-2.1.9.RELEASE.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot-starter-json/2.1.9.RELEASE/spring-boot-starter-json-2.1.9.RELEASE.jar:/home/one/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jdk8/2.9.9/jackson-datatype-jdk8-2.9.9.jar:/home/one/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.9.9/jackson-datatype-jsr310-2.9.9.jar:/home/one/.m2/repository/com/fasterxml/jackson/module/jackson-module-parameter-names/2.9.9/jackson-module-parameter-names-2.9.9.jar:/home/one/.m2/repository/org/springframework/boot/spring-boot-starter-tomcat/2.1.9.RELEASE/spring-boot-starter-tomcat-2.1.9.RELEASE.jar:/home/one/.m2/repository/org/apache/tomcat/embed/tomcat-embed-core/9.0.26/tomcat-embed-core-9.0.26.jar:/home/one/.m2/repository/org/apache/tomcat/embed/tomcat-embed-el/9.0.26/tomcat-embed-el-9.0.26.jar:/home/one/.m2/repository/org/apache/tomcat/embed/tomcat-embed-websocket/9.0.26/tomcat-embed-websocket-9.0.26.jar:/home/one/.m2/repository/org/hibernate/validator/hibernate-validator/6.0.17.Final/hibernate-validator-6.0.17.Final.jar:/home/one/.m2/repository/javax/validation/validation-api/2.0.1.Final/validation-api-2.0.1.Final.jar:/home/one/.m2/repository/org/jboss/logging/jboss-logging/3.3.3.Final/jboss-logging-3.3.3.Final.jar:/home/one/.m2/repository/com/fasterxml/classmate/1.4.0/classmate-1.4.0.jar:/home/one/.m2/repository/org/springframework/spring-web/5.1.10.RELEASE/spring-web-5.1.10.RELEASE.jar:/home/one/.m2/repository/org/springframework/spring-webmvc/5.1.10.RELEASE/spring-webmvc-5.1.10.RELEASE.jar:/home/one/.m2/repository/com/datastax/oss/java-driver-core/4.2.1/java-driver-core-4.2.1.jar:/home/one/.m2/repository/com/datastax/oss/native-protocol/1.4.6/native-protocol-1.4.6.jar:/home/one/.m2/repository/io/netty/netty-handler/4.1.39.Final/netty-handler-4.1.39.Final.jar:/home/one/.m2/repository/io/netty/netty-common/4.1.39.Final/netty-common-4.1.39.Final.jar:/home/one/.m2/repository/io/netty/netty-buffer/4.1.39.Final/netty-buffer-4.1.39.Final.jar:/home/one/.m2/repository/io/netty/netty-transport/4.1.39.Final/netty-transport-4.1.39.Final.jar:/home/one/.m2/repository/io/netty/netty-resolver/4.1.39.Final/netty-resolver-4.1.39.Final.jar:/home/one/.m2/repository/io/netty/netty-codec/4.1.39.Final/netty-codec-4.1.39.Final.jar:/home/one/.m2/repository/com/datastax/oss/java-driver-shaded-guava/25.1-jre/java-driver-shaded-guava-25.1-jre.jar:/home/one/.m2/repository/com/typesafe/config/1.3.4/config-1.3.4.jar:/home/one/.m2/repository/com/github/jnr/jnr-ffi/2.1.10/jnr-ffi-2.1.10.jar:/home/one/.m2/repository/com/github/jnr/jffi/1.2.19/jffi-1.2.19.jar:/home/one/.m2/repository/com/github/jnr/jffi/1.2.19/jffi-1.2.19-native.jar:/home/one/.m2/repository/org/ow2/asm/asm/7.1/asm-7.1.jar:/home/one/.m2/repository/org/ow2/asm/asm-commons/7.1/asm-commons-7.1.jar:/home/one/.m2/repository/org/ow2/asm/asm-analysis/7.1/asm-analysis-7.1.jar:/home/one/.m2/repository/org/ow2/asm/asm-tree/7.1/asm-tree-7.1.jar:/home/one/.m2/repository/org/ow2/asm/asm-util/7.1/asm-util-7.1.jar:/home/one/.m2/repository/com/github/jnr/jnr-a64asm/1.0.0/jnr-a64asm-1.0.0.jar:/home/one/.m2/repository/com/github/jnr/jnr-x86asm/1.0.2/jnr-x86asm-1.0.2.jar:/home/one/.m2/repository/com/github/jnr/jnr-posix/3.0.50/jnr-posix-3.0.50.jar:/home/one/.m2/repository/com/github/jnr/jnr-constants/0.9.12/jnr-constants-0.9.12.jar:/home/one/.m2/repository/org/slf4j/slf4j-api/1.7.28/slf4j-api-1.7.28.jar:/home/one/.m2/repository/io/dropwizard/metrics/metrics-core/4.0.6/metrics-core-4.0.6.jar:/home/one/.m2/repository/org/hdrhistogram/HdrHistogram/2.1.11/HdrHistogram-2.1.11.jar:/home/one/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/one/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/one/.m2/repository/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/home/one/.m2/repository/com/datastax/oss/java-driver-query-builder/4.2.1/java-driver-query-builder-4.2.1.jar:/home/one/.m2/repository/com/datastax/cassandra/cassandra-driver-core/3.6.0/cassandra-driver-core-3.6.0.jar:/home/one/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:
09:03:02.538 [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib
09:03:02.549 [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
09:03:02.549 [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
09:03:02.549 [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
09:03:02.549 [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
09:03:02.549 [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.version=4.15.0-65-generic
09:03:02.550 [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.name=one
09:03:02.553 [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/one
09:03:02.553 [main] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/media/sf_PNY480/javacode/oss-kafka-cassandra-spring
09:03:02.555 [main] INFO org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=127.0.0.1:36547 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@40258c2f
09:03:02.563 [main] DEBUG org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
09:03:02.573 [main] DEBUG org.I0Itec.zkclient.ZkClient - Awaiting connection to Zookeeper server
09:03:02.573 [main] INFO org.I0Itec.zkclient.ZkClient - Waiting for keeper state SyncConnected
09:03:02.584 [main-SendThread(localhost.localdomain:36547)] INFO org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost.localdomain/127.0.0.1:36547. Will not attempt to authenticate using SASL (unknown error)
09:03:02.587 [main-SendThread(localhost.localdomain:36547)] INFO org.apache.zookeeper.ClientCnxn - Socket connection established to localhost.localdomain/127.0.0.1:36547, initiating session
09:03:02.590 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Session establishment request sent on localhost.localdomain/127.0.0.1:36547
09:03:02.603 [NIOServerCxn.Factory:/127.0.0.1:0] INFO org.apache.zookeeper.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:43692
09:03:02.616 [NIOServerCxn.Factory:/127.0.0.1:0] DEBUG org.apache.zookeeper.server.ZooKeeperServer - Session establishment request from client /127.0.0.1:43692 client's lastZxid is 0x0
09:03:02.618 [NIOServerCxn.Factory:/127.0.0.1:0] INFO org.apache.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:43692
09:03:02.630 [SyncThread:0] INFO org.apache.zookeeper.server.persistence.FileTxnLog - Creating new log file: log.1
09:03:02.634 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200000 type:createSession cxid:0x0 zxid:0x1 txntype:-10 reqpath:n/a
09:03:02.650 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200000 type:createSession cxid:0x0 zxid:0x1 txntype:-10 reqpath:n/a
09:03:02.661 [SyncThread:0] INFO org.apache.zookeeper.server.ZooKeeperServer - Established session 0x100055a6a200000 with negotiated timeout 6000 for client /127.0.0.1:43692
09:03:02.661 [main-SendThread(localhost.localdomain:36547)] INFO org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost.localdomain/127.0.0.1:36547, sessionid = 0x100055a6a200000, negotiated timeout = 6000
09:03:02.666 [main-EventThread] DEBUG org.I0Itec.zkclient.ZkClient - Received event: WatchedEvent state:SyncConnected type:None path:null
09:03:02.666 [main-EventThread] INFO org.I0Itec.zkclient.ZkClient - zookeeper state changed (SyncConnected)
09:03:02.666 [main-EventThread] DEBUG org.I0Itec.zkclient.ZkClient - Leaving process event
09:03:02.666 [main] DEBUG org.I0Itec.zkclient.ZkClient - State is SyncConnected
09:03:03.284 [main] INFO kafka.server.KafkaConfig - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-5871668507220914040
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:36547
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

09:03:03.470 [main] INFO kafka.server.KafkaServer - starting
09:03:03.472 [main] INFO kafka.server.KafkaServer - Connecting to zookeeper on 127.0.0.1:36547
09:03:03.501 [main] INFO kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Initializing a new session to 127.0.0.1:36547.
09:03:03.502 [main] INFO org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=127.0.0.1:36547 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6eafb10e
09:03:03.519 [main-SendThread(localhost.localdomain:36547)] INFO org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost.localdomain/127.0.0.1:36547. Will not attempt to authenticate using SASL (unknown error)
09:03:03.520 [NIOServerCxn.Factory:/127.0.0.1:0] INFO org.apache.zookeeper.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:43694
09:03:03.520 [main] DEBUG kafka.utils.KafkaScheduler - Initializing task scheduler.
09:03:03.521 [main-SendThread(localhost.localdomain:36547)] INFO org.apache.zookeeper.ClientCnxn - Socket connection established to localhost.localdomain/127.0.0.1:36547, initiating session
09:03:03.525 [main] INFO kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Waiting until connected.
09:03:03.525 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Session establishment request sent on localhost.localdomain/127.0.0.1:36547
09:03:03.526 [NIOServerCxn.Factory:/127.0.0.1:0] DEBUG org.apache.zookeeper.server.ZooKeeperServer - Session establishment request from client /127.0.0.1:43694 client's lastZxid is 0x0
09:03:03.526 [NIOServerCxn.Factory:/127.0.0.1:0] INFO org.apache.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:43694
09:03:03.527 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:createSession cxid:0x0 zxid:0x2 txntype:-10 reqpath:n/a
09:03:03.527 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:createSession cxid:0x0 zxid:0x2 txntype:-10 reqpath:n/a
09:03:03.531 [SyncThread:0] INFO org.apache.zookeeper.server.ZooKeeperServer - Established session 0x100055a6a200001 with negotiated timeout 6000 for client /127.0.0.1:43694
09:03:03.532 [main-SendThread(localhost.localdomain:36547)] INFO org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost.localdomain/127.0.0.1:36547, sessionid = 0x100055a6a200001, negotiated timeout = 6000
09:03:03.535 [main-EventThread] DEBUG kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Received event: WatchedEvent state:SyncConnected type:None path:null
09:03:03.538 [main] INFO kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Connected.
09:03:03.640 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x1 zxid:0x3 txntype:1 reqpath:n/a
09:03:03.643 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x1 zxid:0x3 txntype:1 reqpath:n/a
09:03:03.648 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/consumers serverPath:/consumers finished:false header:: 1,1  replyHeader:: 1,3,0  request:: '/consumers,,v{s{31,s{'world,'anyone}}},0  response:: '/consumers 
09:03:03.663 [ProcessThread(sid:0 cport:36547):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x100055a6a200001 type:create cxid:0x2 zxid:0x4 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
09:03:03.664 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x2 zxid:0x4 txntype:-1 reqpath:n/a
09:03:03.664 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Ignoring processTxn failure hdr: -1 : error: -101
09:03:03.665 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/ids serverPath:/brokers/ids finished:false header:: 2,1  replyHeader:: 2,4,-101  request:: '/brokers/ids,,v{s{31,s{'world,'anyone}}},0  response::  
09:03:03.667 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x3 zxid:0x5 txntype:1 reqpath:n/a
09:03:03.667 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x3 zxid:0x5 txntype:1 reqpath:n/a
09:03:03.668 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers serverPath:/brokers finished:false header:: 3,1  replyHeader:: 3,5,0  request:: '/brokers,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers 
09:03:03.669 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x4 zxid:0x6 txntype:1 reqpath:n/a
09:03:03.673 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x4 zxid:0x6 txntype:1 reqpath:n/a
09:03:03.674 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/ids serverPath:/brokers/ids finished:false header:: 4,1  replyHeader:: 4,6,0  request:: '/brokers/ids,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/ids 
09:03:03.676 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x5 zxid:0x7 txntype:1 reqpath:n/a
09:03:03.676 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x5 zxid:0x7 txntype:1 reqpath:n/a
09:03:03.677 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/topics serverPath:/brokers/topics finished:false header:: 5,1  replyHeader:: 5,7,0  request:: '/brokers/topics,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics 
09:03:03.679 [ProcessThread(sid:0 cport:36547):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x100055a6a200001 type:create cxid:0x6 zxid:0x8 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
09:03:03.679 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x6 zxid:0x8 txntype:-1 reqpath:n/a
09:03:03.679 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Ignoring processTxn failure hdr: -1 : error: -101
09:03:03.680 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/changes serverPath:/config/changes finished:false header:: 6,1  replyHeader:: 6,8,-101  request:: '/config/changes,,v{s{31,s{'world,'anyone}}},0  response::  
09:03:03.682 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x7 zxid:0x9 txntype:1 reqpath:n/a
09:03:03.682 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x7 zxid:0x9 txntype:1 reqpath:n/a
09:03:03.683 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config serverPath:/config finished:false header:: 7,1  replyHeader:: 7,9,0  request:: '/config,,v{s{31,s{'world,'anyone}}},0  response:: '/config 
09:03:03.684 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x8 zxid:0xa txntype:1 reqpath:n/a
09:03:03.685 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x8 zxid:0xa txntype:1 reqpath:n/a
09:03:03.687 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/changes serverPath:/config/changes finished:false header:: 8,1  replyHeader:: 8,10,0  request:: '/config/changes,,v{s{31,s{'world,'anyone}}},0  response:: '/config/changes 
09:03:03.693 [ProcessThread(sid:0 cport:36547):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x100055a6a200001 type:create cxid:0x9 zxid:0xb txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
09:03:03.693 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x9 zxid:0xb txntype:-1 reqpath:n/a
09:03:03.694 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Ignoring processTxn failure hdr: -1 : error: -101
09:03:03.695 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/admin/delete_topics serverPath:/admin/delete_topics finished:false header:: 9,1  replyHeader:: 9,11,-101  request:: '/admin/delete_topics,,v{s{31,s{'world,'anyone}}},0  response::  
09:03:03.697 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0xa zxid:0xc txntype:1 reqpath:n/a
09:03:03.697 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0xa zxid:0xc txntype:1 reqpath:n/a
09:03:03.699 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/admin serverPath:/admin finished:false header:: 10,1  replyHeader:: 10,12,0  request:: '/admin,,v{s{31,s{'world,'anyone}}},0  response:: '/admin 
09:03:03.702 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0xb zxid:0xd txntype:1 reqpath:n/a
09:03:03.702 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0xb zxid:0xd txntype:1 reqpath:n/a
09:03:03.704 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/admin/delete_topics serverPath:/admin/delete_topics finished:false header:: 11,1  replyHeader:: 11,13,0  request:: '/admin/delete_topics,,v{s{31,s{'world,'anyone}}},0  response:: '/admin/delete_topics 
09:03:03.706 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0xc zxid:0xe txntype:1 reqpath:n/a
09:03:03.706 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0xc zxid:0xe txntype:1 reqpath:n/a
09:03:03.707 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/seqid serverPath:/brokers/seqid finished:false header:: 12,1  replyHeader:: 12,14,0  request:: '/brokers/seqid,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/seqid 
09:03:03.709 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0xd zxid:0xf txntype:1 reqpath:n/a
09:03:03.710 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0xd zxid:0xf txntype:1 reqpath:n/a
09:03:03.711 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/isr_change_notification serverPath:/isr_change_notification finished:false header:: 13,1  replyHeader:: 13,15,0  request:: '/isr_change_notification,,v{s{31,s{'world,'anyone}}},0  response:: '/isr_change_notification 
09:03:03.713 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0xe zxid:0x10 txntype:1 reqpath:n/a
09:03:03.714 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0xe zxid:0x10 txntype:1 reqpath:n/a
09:03:03.715 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/latest_producer_id_block serverPath:/latest_producer_id_block finished:false header:: 14,1  replyHeader:: 14,16,0  request:: '/latest_producer_id_block,,v{s{31,s{'world,'anyone}}},0  response:: '/latest_producer_id_block 
09:03:03.718 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0xf zxid:0x11 txntype:1 reqpath:n/a
09:03:03.718 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0xf zxid:0x11 txntype:1 reqpath:n/a
09:03:03.719 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/log_dir_event_notification serverPath:/log_dir_event_notification finished:false header:: 15,1  replyHeader:: 15,17,0  request:: '/log_dir_event_notification,,v{s{31,s{'world,'anyone}}},0  response:: '/log_dir_event_notification 
09:03:03.720 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x10 zxid:0x12 txntype:1 reqpath:n/a
09:03:03.720 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x10 zxid:0x12 txntype:1 reqpath:n/a
09:03:03.721 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/topics serverPath:/config/topics finished:false header:: 16,1  replyHeader:: 16,18,0  request:: '/config/topics,,v{s{31,s{'world,'anyone}}},0  response:: '/config/topics 
09:03:03.723 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x11 zxid:0x13 txntype:1 reqpath:n/a
09:03:03.723 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x11 zxid:0x13 txntype:1 reqpath:n/a
09:03:03.724 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/clients serverPath:/config/clients finished:false header:: 17,1  replyHeader:: 17,19,0  request:: '/config/clients,,v{s{31,s{'world,'anyone}}},0  response:: '/config/clients 
09:03:03.726 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x12 zxid:0x14 txntype:1 reqpath:n/a
09:03:03.726 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x12 zxid:0x14 txntype:1 reqpath:n/a
09:03:03.726 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/users serverPath:/config/users finished:false header:: 18,1  replyHeader:: 18,20,0  request:: '/config/users,,v{s{31,s{'world,'anyone}}},0  response:: '/config/users 
09:03:03.728 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x13 zxid:0x15 txntype:1 reqpath:n/a
09:03:03.728 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x13 zxid:0x15 txntype:1 reqpath:n/a
09:03:03.729 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/brokers serverPath:/config/brokers finished:false header:: 19,1  replyHeader:: 19,21,0  request:: '/config/brokers,,v{s{31,s{'world,'anyone}}},0  response:: '/config/brokers 
09:03:03.737 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getData cxid:0x14 zxid:0xfffffffffffffffe txntype:unknown reqpath:/cluster/id
09:03:03.737 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getData cxid:0x14 zxid:0xfffffffffffffffe txntype:unknown reqpath:/cluster/id
09:03:03.738 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/cluster/id serverPath:/cluster/id finished:false header:: 20,4  replyHeader:: 20,21,-101  request:: '/cluster/id,F  response::  
09:03:04.159 [ProcessThread(sid:0 cport:36547):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x100055a6a200001 type:create cxid:0x15 zxid:0x16 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
09:03:04.160 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x15 zxid:0x16 txntype:-1 reqpath:n/a
09:03:04.160 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Ignoring processTxn failure hdr: -1 : error: -101
09:03:04.161 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/cluster/id serverPath:/cluster/id finished:false header:: 21,1  replyHeader:: 21,22,-101  request:: '/cluster/id,#7b2276657273696f6e223a2231222c226964223a22353442364c4f4d625137716a79466a57416d5a307177227d,v{s{31,s{'world,'anyone}}},0  response::  
09:03:04.165 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x16 zxid:0x17 txntype:1 reqpath:n/a
09:03:04.165 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x16 zxid:0x17 txntype:1 reqpath:n/a
09:03:04.166 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/cluster serverPath:/cluster finished:false header:: 22,1  replyHeader:: 22,23,0  request:: '/cluster,,v{s{31,s{'world,'anyone}}},0  response:: '/cluster 
09:03:04.169 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x17 zxid:0x18 txntype:1 reqpath:n/a
09:03:04.170 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x17 zxid:0x18 txntype:1 reqpath:n/a
09:03:04.170 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/cluster/id serverPath:/cluster/id finished:false header:: 23,1  replyHeader:: 23,24,0  request:: '/cluster/id,#7b2276657273696f6e223a2231222c226964223a22353442364c4f4d625137716a79466a57416d5a307177227d,v{s{31,s{'world,'anyone}}},0  response:: '/cluster/id 
09:03:04.173 [main] INFO kafka.server.KafkaServer - Cluster ID = 54B6LOMbQ7qjyFjWAmZ0qw
09:03:04.183 [main] WARN kafka.server.BrokerMetadataCheckpoint - No meta.properties file under dir /tmp/kafka-5871668507220914040/meta.properties
09:03:04.199 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getData cxid:0x18 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/brokers/<default>
09:03:04.200 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getData cxid:0x18 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/brokers/<default>
09:03:04.200 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/brokers/<default> serverPath:/config/brokers/<default> finished:false header:: 24,4  replyHeader:: 24,24,-101  request:: '/config/brokers/<default>,F  response::  
09:03:04.259 [main] INFO kafka.server.KafkaConfig - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-5871668507220914040
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:36547
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

09:03:04.273 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getData cxid:0x19 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/brokers/0
09:03:04.273 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getData cxid:0x19 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/brokers/0
09:03:04.274 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/brokers/0 serverPath:/config/brokers/0 finished:false header:: 25,4  replyHeader:: 25,24,-101  request:: '/config/brokers/0,F  response::  
09:03:04.279 [main] INFO kafka.server.KafkaConfig - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-5871668507220914040
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:36547
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

09:03:04.291 [main] DEBUG kafka.utils.KafkaScheduler - Initializing task scheduler.
09:03:04.326 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name Fetch-delayQueue
09:03:04.330 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name Produce-delayQueue
09:03:04.332 [ThrottledChannelReaper-Produce] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper - [ThrottledChannelReaper-Produce]: Starting
09:03:04.333 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name Request-delayQueue
09:03:04.332 [ThrottledChannelReaper-Fetch] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper - [ThrottledChannelReaper-Fetch]: Starting
09:03:04.335 [ThrottledChannelReaper-Request] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper - [ThrottledChannelReaper-Request]: Starting
09:03:04.352 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getChildren2 cxid:0x1a zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics
09:03:04.352 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getChildren2 cxid:0x1a zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics
09:03:04.355 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/topics serverPath:/brokers/topics finished:false header:: 26,12  replyHeader:: 26,24,0  request:: '/brokers/topics,F  response:: v{},s{7,7,1571490183676,1571490183676,0,0,0,0,0,0,7} 
09:03:04.378 [main] INFO kafka.log.LogManager - Loading logs.
09:03:04.389 [main] INFO kafka.log.LogManager - Logs loading complete in 11 ms.
09:03:04.405 [main] INFO kafka.log.LogManager - Starting log cleanup with a period of 300000 ms.
09:03:04.408 [main] DEBUG kafka.utils.KafkaScheduler - Scheduling task kafka-log-retention with initial delay 30000 ms and period 300000 ms.
09:03:04.411 [main] INFO kafka.log.LogManager - Starting log flusher with a default period of 9223372036854775807 ms.
09:03:04.412 [main] DEBUG kafka.utils.KafkaScheduler - Scheduling task kafka-log-flusher with initial delay 30000 ms and period 9223372036854775807 ms.
09:03:04.417 [main] DEBUG kafka.utils.KafkaScheduler - Scheduling task kafka-recovery-point-checkpoint with initial delay 30000 ms and period 60000 ms.
09:03:04.418 [main] DEBUG kafka.utils.KafkaScheduler - Scheduling task kafka-log-start-offset-checkpoint with initial delay 30000 ms and period 60000 ms.
09:03:04.425 [main] DEBUG kafka.utils.KafkaScheduler - Scheduling task kafka-delete-logs with initial delay 30000 ms and period -1 ms.
09:03:04.429 [main] INFO kafka.log.LogCleaner - Starting the log cleaner
09:03:04.476 [kafka-log-cleaner-thread-0] INFO kafka.log.LogCleaner - [kafka-log-cleaner-thread-0]: Starting
09:03:04.499 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name MemoryPoolUtilization
09:03:04.599 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200000 type:ping cxid:0xfffffffffffffffe zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a
09:03:04.600 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200000 type:ping cxid:0xfffffffffffffffe zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a
09:03:04.600 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x100055a6a200000 after 1ms
09:03:05.110 [main] INFO kafka.network.Acceptor - Awaiting socket connections on localhost:39851.
09:03:05.189 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:listener-PLAINTEXTnetworkProcessor-0
09:03:05.190 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:listener-PLAINTEXTnetworkProcessor-0
09:03:05.191 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name successful-authentication:listener-PLAINTEXTnetworkProcessor-0
09:03:05.193 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name failed-authentication:listener-PLAINTEXTnetworkProcessor-0
09:03:05.193 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:listener-PLAINTEXTnetworkProcessor-0
09:03:05.195 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:listener-PLAINTEXTnetworkProcessor-0
09:03:05.211 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:listener-PLAINTEXTnetworkProcessor-0
09:03:05.212 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:listener-PLAINTEXTnetworkProcessor-0
09:03:05.213 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:listener-PLAINTEXTnetworkProcessor-0
09:03:05.237 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:listener-PLAINTEXTnetworkProcessor-1
09:03:05.238 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:listener-PLAINTEXTnetworkProcessor-1
09:03:05.238 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name successful-authentication:listener-PLAINTEXTnetworkProcessor-1
09:03:05.239 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name failed-authentication:listener-PLAINTEXTnetworkProcessor-1
09:03:05.239 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:listener-PLAINTEXTnetworkProcessor-1
09:03:05.240 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:listener-PLAINTEXTnetworkProcessor-1
09:03:05.241 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:listener-PLAINTEXTnetworkProcessor-1
09:03:05.241 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:listener-PLAINTEXTnetworkProcessor-1
09:03:05.242 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:listener-PLAINTEXTnetworkProcessor-1
09:03:05.243 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:listener-PLAINTEXTnetworkProcessor-2
09:03:05.245 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:listener-PLAINTEXTnetworkProcessor-2
09:03:05.246 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name successful-authentication:listener-PLAINTEXTnetworkProcessor-2
09:03:05.250 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name failed-authentication:listener-PLAINTEXTnetworkProcessor-2
09:03:05.250 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:listener-PLAINTEXTnetworkProcessor-2
09:03:05.251 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:listener-PLAINTEXTnetworkProcessor-2
09:03:05.251 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:listener-PLAINTEXTnetworkProcessor-2
09:03:05.252 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:listener-PLAINTEXTnetworkProcessor-2
09:03:05.253 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:listener-PLAINTEXTnetworkProcessor-2
09:03:05.275 [main] INFO kafka.network.SocketServer - [SocketServer brokerId=0] Started 1 acceptor threads
09:03:05.378 [ExpirationReaper-0-Fetch] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Fetch]: Starting
09:03:05.376 [ExpirationReaper-0-Produce] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Produce]: Starting
09:03:05.379 [ExpirationReaper-0-DeleteRecords] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-DeleteRecords]: Starting
09:03:05.411 [main] DEBUG kafka.utils.KafkaScheduler - Scheduling task isr-expiration with initial delay 0 ms and period 5000 ms.
09:03:05.422 [main] DEBUG kafka.utils.KafkaScheduler - Scheduling task isr-change-propagation with initial delay 0 ms and period 2500 ms.
09:03:05.440 [main] DEBUG kafka.utils.KafkaScheduler - Scheduling task shutdown-idle-replica-alter-log-dirs-thread with initial delay 0 ms and period 10000 ms.
09:03:05.466 [LogDirFailureHandler] INFO kafka.server.ReplicaManager$LogDirFailureHandler - [LogDirFailureHandler]: Starting
09:03:05.470 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getChildren2 cxid:0x1b zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids
09:03:05.470 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getChildren2 cxid:0x1b zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids
09:03:05.471 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:ping cxid:0xfffffffffffffffe zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a
09:03:05.471 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:ping cxid:0xfffffffffffffffe zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a
09:03:05.471 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/ids serverPath:/brokers/ids finished:false header:: 27,12  replyHeader:: 27,24,0  request:: '/brokers/ids,F  response:: v{},s{6,6,1571490183669,1571490183669,0,0,0,0,0,0,6} 
09:03:05.472 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x100055a6a200001 after 3ms
09:03:05.618 [main] INFO kafka.zk.KafkaZkClient - Creating /brokers/ids/0 (is it secure? false)
09:03:05.620 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x1c zxid:0x19 txntype:1 reqpath:n/a
09:03:05.621 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x1c zxid:0x19 txntype:1 reqpath:n/a
09:03:05.622 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/ids/0 serverPath:/brokers/ids/0 finished:false header:: 28,1  replyHeader:: 28,25,0  request:: '/brokers/ids/0,#7b226c697374656e65725f73656375726974795f70726f746f636f6c5f6d6170223a7b22504c41494e54455854223a22504c41494e54455854227d2c22656e64706f696e7473223a5b22504c41494e544558543a2f2f6c6f63616c686f73743a3339383531225d2c226a6d785f706f7274223a2d312c22686f7374223a226c6f63616c686f7374222c2274696d657374616d70223a2231353731343930313835353235222c22706f7274223a33393835312c2276657273696f6e223a347d,v{s{31,s{'world,'anyone}}},1  response:: '/brokers/ids/0 
09:03:05.634 [main] INFO kafka.zk.KafkaZkClient - Result of znode creation at /brokers/ids/0 is: OK
09:03:05.637 [main] INFO kafka.zk.KafkaZkClient - Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,39851,ListenerName(PLAINTEXT),PLAINTEXT))
09:03:05.642 [main] WARN kafka.server.BrokerMetadataCheckpoint - No meta.properties file under dir /tmp/kafka-5871668507220914040/meta.properties
09:03:05.794 [controller-event-thread] INFO kafka.controller.ControllerEventManager$ControllerEventThread - [ControllerEventThread controllerId=0] Starting
09:03:05.827 [ExpirationReaper-0-topic] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-topic]: Starting
09:03:05.837 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:exists cxid:0x1d zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:03:05.837 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:exists cxid:0x1d zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:03:05.840 [ExpirationReaper-0-Heartbeat] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Heartbeat]: Starting
09:03:05.843 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/controller serverPath:/controller finished:false header:: 29,3  replyHeader:: 29,25,-101  request:: '/controller,T  response::  
09:03:05.844 [ExpirationReaper-0-Rebalance] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Rebalance]: Starting
09:03:05.850 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getData cxid:0x1e zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:03:05.850 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getData cxid:0x1e zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:03:05.851 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/controller serverPath:/controller finished:false header:: 30,4  replyHeader:: 30,25,-101  request:: '/controller,T  response::  
09:03:05.853 [controller-event-thread] INFO kafka.zk.KafkaZkClient - Creating /controller (is it secure? false)
09:03:05.856 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x1f zxid:0x1a txntype:1 reqpath:n/a
09:03:05.857 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x1f zxid:0x1a txntype:1 reqpath:n/a
09:03:05.858 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Got notification sessionid:0x100055a6a200001
09:03:05.858 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Got WatchedEvent state:SyncConnected type:NodeCreated path:/controller for sessionid 0x100055a6a200001
09:03:05.858 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/controller serverPath:/controller finished:false header:: 31,1  replyHeader:: 31,26,0  request:: '/controller,#7b2276657273696f6e223a312c2262726f6b65726964223a302c2274696d657374616d70223a2231353731343930313835383435227d,v{s{31,s{'world,'anyone}}},1  response:: '/controller 
09:03:05.858 [main-EventThread] DEBUG kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Received event: WatchedEvent state:SyncConnected type:NodeCreated path:/controller
09:03:05.862 [controller-event-thread] INFO kafka.zk.KafkaZkClient - Result of znode creation at /controller is: OK
09:03:05.864 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] 0 successfully elected as the controller
09:03:05.865 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Reading controller epoch from ZooKeeper
09:03:05.866 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getData cxid:0x20 zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller_epoch
09:03:05.866 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getData cxid:0x20 zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller_epoch
09:03:05.867 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/controller_epoch serverPath:/controller_epoch finished:false header:: 32,4  replyHeader:: 32,26,-101  request:: '/controller_epoch,F  response::  
09:03:05.869 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Incrementing controller epoch in ZooKeeper
09:03:05.869 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getData cxid:0x21 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/__consumer_offsets
09:03:05.869 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getData cxid:0x21 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/__consumer_offsets
09:03:05.870 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/topics/__consumer_offsets serverPath:/brokers/topics/__consumer_offsets finished:false header:: 33,4  replyHeader:: 33,26,-101  request:: '/brokers/topics/__consumer_offsets,F  response::  
09:03:05.877 [ProcessThread(sid:0 cport:36547):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x100055a6a200001 type:setData cxid:0x22 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
09:03:05.878 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:setData cxid:0x22 zxid:0x1b txntype:-1 reqpath:n/a
09:03:05.878 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Ignoring processTxn failure hdr: -1 : error: -101
09:03:05.879 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/controller_epoch serverPath:/controller_epoch finished:false header:: 34,5  replyHeader:: 34,27,-101  request:: '/controller_epoch,#31,0  response::  
09:03:05.885 [main] INFO kafka.coordinator.group.GroupCoordinator - [GroupCoordinator 0]: Starting up.
09:03:05.885 [main] DEBUG kafka.utils.KafkaScheduler - Initializing task scheduler.
09:03:05.886 [main] DEBUG kafka.utils.KafkaScheduler - Scheduling task delete-expired-group-metadata with initial delay 0 ms and period 600000 ms.
09:03:05.888 [main] INFO kafka.coordinator.group.GroupCoordinator - [GroupCoordinator 0]: Startup complete.
09:03:05.890 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x23 zxid:0x1c txntype:1 reqpath:n/a
09:03:05.890 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x23 zxid:0x1c txntype:1 reqpath:n/a
09:03:05.891 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/controller_epoch serverPath:/controller_epoch finished:false header:: 35,1  replyHeader:: 35,28,0  request:: '/controller_epoch,#31,v{s{31,s{'world,'anyone}}},0  response:: '/controller_epoch 
09:03:05.896 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getData cxid:0x24 zxid:0xfffffffffffffffe txntype:unknown reqpath:/latest_producer_id_block
09:03:05.897 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getData cxid:0x24 zxid:0xfffffffffffffffe txntype:unknown reqpath:/latest_producer_id_block
09:03:05.897 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/latest_producer_id_block serverPath:/latest_producer_id_block finished:false header:: 36,4  replyHeader:: 36,28,0  request:: '/latest_producer_id_block,F  response:: ,s{16,16,1571490183713,1571490183713,0,0,0,0,0,0,16} 
09:03:05.899 [main] DEBUG kafka.coordinator.transaction.ProducerIdManager - [ProducerId Manager 0]: There is no producerId block yet (Zk path version 0), creating the first block
09:03:05.899 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Epoch incremented to 1
09:03:05.904 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Registering handlers
09:03:05.909 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:exists cxid:0x25 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/preferred_replica_election
09:03:05.909 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:exists cxid:0x25 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/preferred_replica_election
09:03:05.909 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/admin/preferred_replica_election serverPath:/admin/preferred_replica_election finished:false header:: 37,3  replyHeader:: 37,28,-101  request:: '/admin/preferred_replica_election,T  response::  
09:03:05.911 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:exists cxid:0x26 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/reassign_partitions
09:03:05.911 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:exists cxid:0x26 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/reassign_partitions
09:03:05.912 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/admin/reassign_partitions serverPath:/admin/reassign_partitions finished:false header:: 38,3  replyHeader:: 38,28,-101  request:: '/admin/reassign_partitions,T  response::  
09:03:05.915 [group-metadata-manager-0] INFO kafka.coordinator.group.GroupMetadataManager - [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 28 milliseconds.
09:03:05.915 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Deleting log dir event notifications
09:03:05.916 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getChildren2 cxid:0x27 zxid:0xfffffffffffffffe txntype:unknown reqpath:/log_dir_event_notification
09:03:05.917 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getChildren2 cxid:0x27 zxid:0xfffffffffffffffe txntype:unknown reqpath:/log_dir_event_notification
09:03:05.917 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/log_dir_event_notification serverPath:/log_dir_event_notification finished:false header:: 39,12  replyHeader:: 39,28,0  request:: '/log_dir_event_notification,T  response:: v{},s{17,17,1571490183717,1571490183717,0,0,0,0,0,0,17} 
09:03:05.919 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:setData cxid:0x28 zxid:0x1d txntype:5 reqpath:n/a
09:03:05.920 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:setData cxid:0x28 zxid:0x1d txntype:5 reqpath:n/a
09:03:05.920 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/latest_producer_id_block serverPath:/latest_producer_id_block finished:false header:: 40,5  replyHeader:: 40,29,0  request:: '/latest_producer_id_block,#7b2276657273696f6e223a312c2262726f6b6572223a302c22626c6f636b5f7374617274223a2230222c22626c6f636b5f656e64223a22393939227d,0  response:: s{16,29,1571490183713,1571490185917,1,0,0,0,60,0,16} 
09:03:05.922 [main] DEBUG kafka.zk.KafkaZkClient - Conditional update of path /latest_producer_id_block with value {"version":1,"broker":0,"block_start":"0","block_end":"999"} and expected version 0 succeeded, returning the new version: 1
09:03:05.924 [main] INFO kafka.coordinator.transaction.ProducerIdManager - [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
09:03:05.925 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Deleting isr change notifications
09:03:05.927 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getChildren2 cxid:0x29 zxid:0xfffffffffffffffe txntype:unknown reqpath:/isr_change_notification
09:03:05.928 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getChildren2 cxid:0x29 zxid:0xfffffffffffffffe txntype:unknown reqpath:/isr_change_notification
09:03:05.928 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/isr_change_notification serverPath:/isr_change_notification finished:false header:: 41,12  replyHeader:: 41,29,0  request:: '/isr_change_notification,T  response:: v{},s{15,15,1571490183709,1571490183709,0,0,0,0,0,0,15} 
09:03:05.931 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getData cxid:0x2a zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/__transaction_state
09:03:05.931 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getData cxid:0x2a zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/__transaction_state
09:03:05.932 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/topics/__transaction_state serverPath:/brokers/topics/__transaction_state finished:false header:: 42,4  replyHeader:: 42,29,-101  request:: '/brokers/topics/__transaction_state,F  response::  
09:03:05.936 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Initializing controller context
09:03:05.938 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getChildren2 cxid:0x2b zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids
09:03:05.938 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getChildren2 cxid:0x2b zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids
09:03:05.938 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/ids serverPath:/brokers/ids finished:false header:: 43,12  replyHeader:: 43,29,0  request:: '/brokers/ids,T  response:: v{'0},s{6,6,1571490183669,1571490183669,0,1,0,0,0,1,25} 
09:03:05.938 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
09:03:05.944 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getData cxid:0x2c zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids/0
09:03:05.944 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getData cxid:0x2c zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids/0
09:03:05.945 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/ids/0 serverPath:/brokers/ids/0 finished:false header:: 44,4  replyHeader:: 44,29,0  request:: '/brokers/ids/0,F  response:: #7b226c697374656e65725f73656375726974795f70726f746f636f6c5f6d6170223a7b22504c41494e54455854223a22504c41494e54455854227d2c22656e64706f696e7473223a5b22504c41494e544558543a2f2f6c6f63616c686f73743a3339383531225d2c226a6d785f706f7274223a2d312c22686f7374223a226c6f63616c686f7374222c2274696d657374616d70223a2231353731343930313835353235222c22706f7274223a33393835312c2276657273696f6e223a347d,s{25,25,1571490185619,1571490185619,0,0,0,72063479923605505,190,0,25} 
09:03:05.949 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
09:03:05.949 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name successful-authentication:
09:03:05.950 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name failed-authentication:
09:03:05.955 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
09:03:05.955 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
09:03:05.956 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
09:03:05.957 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
09:03:05.963 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
09:03:06.008 [main] INFO kafka.coordinator.transaction.TransactionCoordinator - [TransactionCoordinator id=0] Starting up.
09:03:06.009 [main] DEBUG kafka.utils.KafkaScheduler - Initializing task scheduler.
09:03:06.023 [main] DEBUG kafka.utils.KafkaScheduler - Scheduling task transaction-abort with initial delay 60000 ms and period 60000 ms.
09:03:06.025 [main] DEBUG kafka.utils.KafkaScheduler - Scheduling task transactionalId-expiration with initial delay 3600000 ms and period 3600000 ms.
09:03:06.036 [main] INFO kafka.coordinator.transaction.TransactionCoordinator - [TransactionCoordinator id=0] Startup complete.
09:03:06.037 [TxnMarkerSenderThread-0] INFO kafka.coordinator.transaction.TransactionMarkerChannelManager - [Transaction Marker Channel Manager 0]: Starting
09:03:06.209 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getChildren2 cxid:0x2d zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics
09:03:06.209 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getChildren2 cxid:0x2d zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics
09:03:06.210 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/topics serverPath:/brokers/topics finished:false header:: 45,12  replyHeader:: 45,29,0  request:: '/brokers/topics,T  response:: v{},s{7,7,1571490183676,1571490183676,0,0,0,0,0,0,7} 
09:03:06.235 [controller-event-thread] DEBUG kafka.controller.KafkaController - [Controller id=0] Register BrokerModifications handler for Set(0)
09:03:06.239 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:exists cxid:0x2e zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids/0
09:03:06.239 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:exists cxid:0x2e zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids/0
09:03:06.240 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/ids/0 serverPath:/brokers/ids/0 finished:false header:: 46,3  replyHeader:: 46,29,0  request:: '/brokers/ids/0,T  response:: s{25,25,1571490185619,1571490185619,0,0,0,72063479923605505,190,0,25} 
09:03:06.287 [controller-event-thread] DEBUG kafka.controller.ControllerChannelManager - [Channel manager on controller 0]: Controller 0 trying to connect to broker 0
09:03:06.321 [/config/changes-event-process-thread] INFO kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread - [/config/changes-event-process-thread]: Starting
09:03:06.323 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getChildren2 cxid:0x2f zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics
09:03:06.323 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getChildren2 cxid:0x2f zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics
09:03:06.324 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getChildren2 cxid:0x30 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/changes
09:03:06.324 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getChildren2 cxid:0x30 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/changes
09:03:06.325 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/topics serverPath:/config/topics finished:false header:: 47,12  replyHeader:: 47,29,0  request:: '/config/topics,F  response:: v{},s{18,18,1571490183719,1571490183719,0,0,0,0,0,0,18} 
09:03:06.325 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/changes serverPath:/config/changes finished:false header:: 48,12  replyHeader:: 48,29,0  request:: '/config/changes,T  response:: v{},s{10,10,1571490183684,1571490183684,0,0,0,0,0,0,10} 
09:03:06.329 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getChildren2 cxid:0x31 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/clients
09:03:06.329 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getChildren2 cxid:0x31 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/clients
09:03:06.329 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:broker-id-0
09:03:06.330 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/clients serverPath:/config/clients finished:false header:: 49,12  replyHeader:: 49,29,0  request:: '/config/clients,F  response:: v{},s{19,19,1571490183722,1571490183722,0,0,0,0,0,0,19} 
09:03:06.331 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getChildren2 cxid:0x32 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/users
09:03:06.331 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getChildren2 cxid:0x32 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/users
09:03:06.332 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/users serverPath:/config/users finished:false header:: 50,12  replyHeader:: 50,29,0  request:: '/config/users,F  response:: v{},s{20,20,1571490183725,1571490183725,0,0,0,0,0,0,20} 
09:03:06.336 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:broker-id-0
09:03:06.336 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name successful-authentication:broker-id-0
09:03:06.336 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name failed-authentication:broker-id-0
09:03:06.337 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:broker-id-0
09:03:06.337 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:broker-id-0
09:03:06.337 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:broker-id-0
09:03:06.337 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:broker-id-0
09:03:06.338 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:broker-id-0
09:03:06.341 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getChildren2 cxid:0x33 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/users
09:03:06.341 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getChildren2 cxid:0x33 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/users
09:03:06.341 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/users serverPath:/config/users finished:false header:: 51,12  replyHeader:: 51,29,0  request:: '/config/users,F  response:: v{},s{20,20,1571490183725,1571490183725,0,0,0,0,0,0,20} 
09:03:06.346 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getChildren2 cxid:0x34 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/brokers
09:03:06.346 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getChildren2 cxid:0x34 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/brokers
09:03:06.347 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/brokers serverPath:/config/brokers finished:false header:: 52,12  replyHeader:: 52,29,0  request:: '/config/brokers,F  response:: v{},s{21,21,1571490183727,1571490183727,0,0,0,0,0,0,21} 
09:03:06.373 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getData cxid:0x35 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/reassign_partitions
09:03:06.373 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getData cxid:0x35 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/reassign_partitions
09:03:06.374 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/admin/reassign_partitions serverPath:/admin/reassign_partitions finished:false header:: 53,4  replyHeader:: 53,29,-101  request:: '/admin/reassign_partitions,T  response::  
09:03:06.377 [main] INFO kafka.network.SocketServer - [SocketServer brokerId=0] Started processors for 1 acceptors
09:03:06.379 [Controller-0-to-broker-0-send-thread] INFO kafka.controller.RequestSendThread - [RequestSendThread controllerId=0] Starting
09:03:06.404 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Partitions being reassigned: Map()
09:03:06.407 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Currently active brokers in the cluster: Set(0)
09:03:06.409 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Currently shutting brokers in the cluster: Set()
09:03:06.411 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Current list of topics in the cluster: Set()
09:03:06.414 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Fetching topic deletions in progress
09:03:06.416 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getChildren2 cxid:0x36 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/delete_topics
09:03:06.416 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
09:03:06.416 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
09:03:06.416 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getChildren2 cxid:0x36 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/delete_topics
09:03:06.416 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/admin/delete_topics serverPath:/admin/delete_topics finished:false header:: 54,12  replyHeader:: 54,29,0  request:: '/admin/delete_topics,T  response:: v{},s{13,13,1571490183701,1571490183701,0,0,0,0,0,0,13} 
09:03:06.420 [main] INFO kafka.server.KafkaServer - [KafkaServer id=0] started
09:03:06.429 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] List of topics to be deleted: 
09:03:06.430 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] List of topics ineligible for deletion: 
09:03:06.431 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Initializing topic deletion manager
09:03:06.433 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Sending update metadata request
09:03:06.435 [main] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:39851]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

09:03:06.483 [Controller-0-to-broker-0-send-thread] DEBUG org.apache.kafka.clients.NetworkClient - [Controller id=0, targetBrokerId=0] Initiating connection to node localhost:39851 (id: 0 rack: null)
09:03:06.484 [controller-event-thread] INFO kafka.controller.ReplicaStateMachine - [ReplicaStateMachine controllerId=0] Initializing replica state
09:03:06.492 [kafka-socket-acceptor-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Acceptor - Accepted connection from /127.0.0.1:38158 on /127.0.0.1:39851 and assigned it to processor 0, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [102400|102400]
09:03:06.504 [controller-event-thread] INFO kafka.controller.ReplicaStateMachine - [ReplicaStateMachine controllerId=0] Triggering online replica state changes
09:03:06.521 [Controller-0-to-broker-0-send-thread] DEBUG org.apache.kafka.common.network.Selector - [Controller id=0, targetBrokerId=0] Created socket with SO_RCVBUF = 530904, SO_SNDBUF = 1313280, SO_TIMEOUT = 0 to node 0
09:03:06.521 [Controller-0-to-broker-0-send-thread] DEBUG org.apache.kafka.clients.NetworkClient - [Controller id=0, targetBrokerId=0] Completed connection to node 0. Ready.
09:03:06.533 [Controller-0-to-broker-0-send-thread] INFO kafka.controller.RequestSendThread - [RequestSendThread controllerId=0] Controller 0 connected to localhost:39851 (id: 0 rack: null) for sending state change requests
09:03:06.541 [controller-event-thread] INFO kafka.controller.ReplicaStateMachine - [ReplicaStateMachine controllerId=0] Started replica state machine with initial state -> Map()
09:03:06.543 [controller-event-thread] INFO kafka.controller.PartitionStateMachine - [PartitionStateMachine controllerId=0] Initializing partition state
09:03:06.546 [controller-event-thread] INFO kafka.controller.PartitionStateMachine - [PartitionStateMachine controllerId=0] Triggering online partition state changes
09:03:06.563 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Processor - Processor 0 listening to new connection from /127.0.0.1:38158
09:03:06.594 [controller-event-thread] INFO kafka.controller.PartitionStateMachine - [PartitionStateMachine controllerId=0] Started partition state machine with initial state -> Map()
09:03:06.595 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Ready to serve as the new controller with epoch 1
09:03:06.599 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Removing partitions Set() from the list of reassigned partitions in zookeeper
09:03:06.601 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions
09:03:06.602 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200000 type:ping cxid:0xfffffffffffffffe zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a
09:03:06.602 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200000 type:ping cxid:0xfffffffffffffffe zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a
09:03:06.603 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x100055a6a200000 after 0ms
09:03:06.618 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
09:03:06.619 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
09:03:06.619 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name successful-authentication:
09:03:06.619 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name failed-authentication:
09:03:06.620 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
09:03:06.620 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
09:03:06.620 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
09:03:06.620 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
09:03:06.621 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
09:03:06.621 [main] DEBUG org.apache.kafka.clients.admin.internals.AdminMetadataManager - [AdminClient clientId=adminclient-1] Setting bootstrap cluster metadata Cluster(id = null, nodes = [127.0.0.1:39851 (id: -1 rack: null)], partitions = [], controller = null).
09:03:06.632 [ProcessThread(sid:0 cport:36547):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x100055a6a200001 type:delete cxid:0x37 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions
09:03:06.635 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:delete cxid:0x37 zxid:0x1e txntype:-1 reqpath:n/a
09:03:06.635 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Ignoring processTxn failure hdr: -1 : error: -101
09:03:06.647 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
09:03:06.647 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
09:03:06.648 [main] DEBUG org.apache.kafka.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Kafka admin client initialized
09:03:06.650 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/admin/reassign_partitions serverPath:/admin/reassign_partitions finished:false header:: 55,2  replyHeader:: 55,30,-101  request:: '/admin/reassign_partitions,-1  response:: null
09:03:06.655 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getData cxid:0x38 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/preferred_replica_election
09:03:06.655 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getData cxid:0x38 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/preferred_replica_election
09:03:06.660 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating connection to node 127.0.0.1:39851 (id: -1 rack: null)
09:03:06.663 [kafka-socket-acceptor-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Acceptor - Accepted connection from /127.0.0.1:38160 on /127.0.0.1:39851 and assigned it to processor 1, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [102400|102400]
09:03:06.673 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/admin/preferred_replica_election serverPath:/admin/preferred_replica_election finished:false header:: 56,4  replyHeader:: 56,30,-101  request:: '/admin/preferred_replica_election,T  response::  
09:03:06.674 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
09:03:06.677 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
09:03:06.678 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
09:03:06.678 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.network.Selector - [AdminClient clientId=adminclient-1] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
09:03:06.678 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Completed connection to node -1. Fetching API versions.
09:03:06.679 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node -1.
09:03:06.680 [main] DEBUG org.apache.kafka.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Queueing Call(callName=createTopics, deadlineMs=1571490306676) with a timeout 120000 ms from now.
09:03:06.684 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG kafka.network.Processor - Processor 1 listening to new connection from /127.0.0.1:38160
09:03:06.689 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Partitions undergoing preferred replica election: 
09:03:06.691 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Partitions that completed preferred replica election: 
09:03:06.692 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
09:03:06.693 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Resuming preferred replica election for partitions: 
09:03:06.696 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Starting preferred replica leader election for partitions 
09:03:06.699 [ProcessThread(sid:0 cport:36547):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x100055a6a200001 type:delete cxid:0x39 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
09:03:06.700 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:delete cxid:0x39 zxid:0x1f txntype:-1 reqpath:n/a
09:03:06.700 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Ignoring processTxn failure hdr: -1 : error: -101
09:03:06.701 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/admin/preferred_replica_election serverPath:/admin/preferred_replica_election finished:false header:: 57,2  replyHeader:: 57,31,-101  request:: '/admin/preferred_replica_election,-1  response:: null
09:03:06.713 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Recorded API versions for node -1: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
09:03:06.716 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Starting the controller scheduler
09:03:06.716 [controller-event-thread] DEBUG kafka.utils.KafkaScheduler - Initializing task scheduler.
09:03:06.718 [controller-event-thread] DEBUG kafka.utils.KafkaScheduler - Scheduling task auto-leader-rebalance-task with initial delay 5000 ms and period -1000 ms.
09:03:06.726 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:exists cxid:0x3a zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:03:06.726 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:exists cxid:0x3a zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:03:06.726 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/controller serverPath:/controller finished:false header:: 58,3  replyHeader:: 58,31,0  request:: '/controller,T  response:: s{26,26,1571490185855,1571490185855,0,0,0,72063479923605505,54,0,26} 
09:03:06.728 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getData cxid:0x3b zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:03:06.728 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getData cxid:0x3b zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:03:06.728 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/controller serverPath:/controller finished:false header:: 59,4  replyHeader:: 59,31,0  request:: '/controller,T  response:: #7b2276657273696f6e223a312c2262726f6b65726964223a302c2274696d657374616d70223a2231353731343930313835383435227d,s{26,26,1571490185855,1571490185855,0,0,0,72063479923605505,54,0,26} 
09:03:06.733 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=UPDATE_METADATA, apiVersion=4, clientId=0, correlationId=0) -- {controller_id=0,controller_epoch=1,partition_states=[],live_brokers=[{id=0,end_points=[{port=39851,host=localhost,listener_name=PLAINTEXT,security_protocol_type=0}],rack=null}]},response:{error_code=0} from connection 127.0.0.1:39851-127.0.0.1:38158-0;totalTime:107.108,requestQueueTime:20.942,localTime:76.138,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.36,sendTime:10.138,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:03:06.733 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=API_VERSIONS, apiVersion=2, clientId=adminclient-1, correlationId=0) -- {},response:{error_code=0,api_versions=[{api_key=0,min_version=0,max_version=6},{api_key=1,min_version=0,max_version=8},{api_key=2,min_version=0,max_version=3},{api_key=3,min_version=0,max_version=6},{api_key=4,min_version=0,max_version=1},{api_key=5,min_version=0,max_version=0},{api_key=6,min_version=0,max_version=4},{api_key=7,min_version=0,max_version=1},{api_key=8,min_version=0,max_version=4},{api_key=9,min_version=0,max_version=4},{api_key=10,min_version=0,max_version=2},{api_key=11,min_version=0,max_version=3},{api_key=12,min_version=0,max_version=2},{api_key=13,min_version=0,max_version=2},{api_key=14,min_version=0,max_version=2},{api_key=15,min_version=0,max_version=2},{api_key=16,min_version=0,max_version=2},{api_key=17,min_version=0,max_version=1},{api_key=18,min_version=0,max_version=2},{api_key=19,min_version=0,max_version=3},{api_key=20,min_version=0,max_version=2},{api_key=21,min_version=0,max_version=1},{api_key=22,min_version=0,max_version=1},{api_key=23,min_version=0,max_version=1},{api_key=24,min_version=0,max_version=1},{api_key=25,min_version=0,max_version=1},{api_key=26,min_version=0,max_version=1},{api_key=27,min_version=0,max_version=0},{api_key=28,min_version=0,max_version=1},{api_key=29,min_version=0,max_version=1},{api_key=30,min_version=0,max_version=1},{api_key=31,min_version=0,max_version=1},{api_key=32,min_version=0,max_version=2},{api_key=33,min_version=0,max_version=1},{api_key=34,min_version=0,max_version=1},{api_key=35,min_version=0,max_version=1},{api_key=36,min_version=0,max_version=0},{api_key=37,min_version=0,max_version=1},{api_key=38,min_version=0,max_version=1},{api_key=39,min_version=0,max_version=1},{api_key=40,min_version=0,max_version=1},{api_key=41,min_version=0,max_version=1},{api_key=42,min_version=0,max_version=1}],throttle_time_ms=0} from connection 127.0.0.1:39851-127.0.0.1:38160-0;totalTime:30.796,requestQueueTime:0.259,localTime:22.464,remoteTime:0.0,throttleTime:18.904,responseQueueTime:0.173,sendTime:8.447,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:03:06.737 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:exists cxid:0x3c zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/reassign_partitions
09:03:06.737 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:exists cxid:0x3c zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/reassign_partitions
09:03:06.737 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/admin/reassign_partitions serverPath:/admin/reassign_partitions finished:false header:: 60,3  replyHeader:: 60,31,-101  request:: '/admin/reassign_partitions,T  response::  
09:03:06.739 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:exists cxid:0x3d zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/preferred_replica_election
09:03:06.739 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:exists cxid:0x3d zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/preferred_replica_election
09:03:06.740 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/admin/preferred_replica_election serverPath:/admin/preferred_replica_election finished:false header:: 61,3  replyHeader:: 61,31,-101  request:: '/admin/preferred_replica_election,T  response::  
09:03:06.761 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.admin.internals.AdminMetadataManager - [AdminClient clientId=adminclient-1] Updating cluster metadata to Cluster(id = 54B6LOMbQ7qjyFjWAmZ0qw, nodes = [localhost:39851 (id: 0 rack: null)], partitions = [], controller = localhost:39851 (id: 0 rack: null))
09:03:06.761 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=1) -- {topics=[],allow_auto_topic_creation=true},response:{throttle_time_ms=0,brokers=[{node_id=0,host=localhost,port=39851,rack=null}],cluster_id=54B6LOMbQ7qjyFjWAmZ0qw,controller_id=0,topic_metadata=[]} from connection 127.0.0.1:39851-127.0.0.1:38160-0;totalTime:20.717,requestQueueTime:0.602,localTime:11.623,remoteTime:0.0,throttleTime:2.886,responseQueueTime:8.044,sendTime:0.49,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:03:06.761 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating connection to node localhost:39851 (id: 0 rack: null)
09:03:06.762 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
09:03:06.762 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
09:03:06.763 [kafka-socket-acceptor-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Acceptor - Accepted connection from /127.0.0.1:38162 on /127.0.0.1:39851 and assigned it to processor 2, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [102400|102400]
09:03:06.763 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG kafka.network.Processor - Processor 2 listening to new connection from /127.0.0.1:38162
09:03:06.763 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
09:03:06.764 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.network.Selector - [AdminClient clientId=adminclient-1] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
09:03:06.764 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Completed connection to node 0. Fetching API versions.
09:03:06.764 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node 0.
09:03:06.766 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=API_VERSIONS, apiVersion=2, clientId=adminclient-1, correlationId=2) -- {},response:{error_code=0,api_versions=[{api_key=0,min_version=0,max_version=6},{api_key=1,min_version=0,max_version=8},{api_key=2,min_version=0,max_version=3},{api_key=3,min_version=0,max_version=6},{api_key=4,min_version=0,max_version=1},{api_key=5,min_version=0,max_version=0},{api_key=6,min_version=0,max_version=4},{api_key=7,min_version=0,max_version=1},{api_key=8,min_version=0,max_version=4},{api_key=9,min_version=0,max_version=4},{api_key=10,min_version=0,max_version=2},{api_key=11,min_version=0,max_version=3},{api_key=12,min_version=0,max_version=2},{api_key=13,min_version=0,max_version=2},{api_key=14,min_version=0,max_version=2},{api_key=15,min_version=0,max_version=2},{api_key=16,min_version=0,max_version=2},{api_key=17,min_version=0,max_version=1},{api_key=18,min_version=0,max_version=2},{api_key=19,min_version=0,max_version=3},{api_key=20,min_version=0,max_version=2},{api_key=21,min_version=0,max_version=1},{api_key=22,min_version=0,max_version=1},{api_key=23,min_version=0,max_version=1},{api_key=24,min_version=0,max_version=1},{api_key=25,min_version=0,max_version=1},{api_key=26,min_version=0,max_version=1},{api_key=27,min_version=0,max_version=0},{api_key=28,min_version=0,max_version=1},{api_key=29,min_version=0,max_version=1},{api_key=30,min_version=0,max_version=1},{api_key=31,min_version=0,max_version=1},{api_key=32,min_version=0,max_version=2},{api_key=33,min_version=0,max_version=1},{api_key=34,min_version=0,max_version=1},{api_key=35,min_version=0,max_version=1},{api_key=36,min_version=0,max_version=0},{api_key=37,min_version=0,max_version=1},{api_key=38,min_version=0,max_version=1},{api_key=39,min_version=0,max_version=1},{api_key=40,min_version=0,max_version=1},{api_key=41,min_version=0,max_version=1},{api_key=42,min_version=0,max_version=1}],throttle_time_ms=0} from connection 127.0.0.1:39851-127.0.0.1:38162-0;totalTime:1.483,requestQueueTime:0.172,localTime:0.97,remoteTime:0.0,throttleTime:0.865,responseQueueTime:0.111,sendTime:0.275,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:03:06.767 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Recorded API versions for node 0: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
09:03:06.803 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:exists cxid:0x3e zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/media-object-test
09:03:06.803 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:exists cxid:0x3e zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/media-object-test
09:03:06.803 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/topics/media-object-test serverPath:/brokers/topics/media-object-test finished:false header:: 62,3  replyHeader:: 62,31,-101  request:: '/brokers/topics/media-object-test,F  response::  
09:03:06.815 [ProcessThread(sid:0 cport:36547):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x100055a6a200001 type:setData cxid:0x3f zxid:0x20 txntype:-1 reqpath:n/a Error Path:/config/topics/media-object-test Error:KeeperErrorCode = NoNode for /config/topics/media-object-test
09:03:06.816 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:setData cxid:0x3f zxid:0x20 txntype:-1 reqpath:n/a
09:03:06.816 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Ignoring processTxn failure hdr: -1 : error: -101
09:03:06.817 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/topics/media-object-test serverPath:/config/topics/media-object-test finished:false header:: 63,5  replyHeader:: 63,32,-101  request:: '/config/topics/media-object-test,#7b2276657273696f6e223a312c22636f6e666967223a7b7d7d,-1  response::  
09:03:06.820 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x40 zxid:0x21 txntype:1 reqpath:n/a
09:03:06.820 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x40 zxid:0x21 txntype:1 reqpath:n/a
09:03:06.821 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/topics/media-object-test serverPath:/config/topics/media-object-test finished:false header:: 64,1  replyHeader:: 64,33,0  request:: '/config/topics/media-object-test,#7b2276657273696f6e223a312c22636f6e666967223a7b7d7d,v{s{31,s{'world,'anyone}}},0  response:: '/config/topics/media-object-test 
09:03:06.825 [kafka-request-handler-4] INFO kafka.zk.AdminZkClient - Topic creation Map(media-object-test-1 -> ArrayBuffer(0), media-object-test-0 -> ArrayBuffer(0))
09:03:06.845 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x41 zxid:0x22 txntype:1 reqpath:n/a
09:03:06.846 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x41 zxid:0x22 txntype:1 reqpath:n/a
09:03:06.846 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Got notification sessionid:0x100055a6a200001
09:03:06.846 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Got WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/brokers/topics for sessionid 0x100055a6a200001
09:03:06.846 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/topics/media-object-test serverPath:/brokers/topics/media-object-test finished:false header:: 65,1  replyHeader:: 65,34,0  request:: '/brokers/topics/media-object-test,#7b2276657273696f6e223a312c22706172746974696f6e73223a7b2231223a5b305d2c2230223a5b305d7d7d,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/media-object-test 
09:03:06.847 [main-EventThread] DEBUG kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Received event: WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/brokers/topics
09:03:06.851 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getChildren2 cxid:0x42 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics
09:03:06.851 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getChildren2 cxid:0x42 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics
09:03:06.852 [kafka-request-handler-4] DEBUG kafka.zk.AdminZkClient - Updated path /brokers/topics/media-object-test with Map(media-object-test-1 -> ArrayBuffer(0), media-object-test-0 -> ArrayBuffer(0)) for replica assignment
09:03:06.852 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/topics serverPath:/brokers/topics finished:false header:: 66,12  replyHeader:: 66,34,0  request:: '/brokers/topics,T  response:: v{'media-object-test},s{7,7,1571490183676,1571490183676,0,1,0,0,0,1,34} 
09:03:06.870 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getData cxid:0x43 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/media-object-test
09:03:06.871 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getData cxid:0x43 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/media-object-test
09:03:06.872 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/topics/media-object-test serverPath:/brokers/topics/media-object-test finished:false header:: 67,4  replyHeader:: 67,34,0  request:: '/brokers/topics/media-object-test,T  response:: #7b2276657273696f6e223a312c22706172746974696f6e73223a7b2231223a5b305d2c2230223a5b305d7d7d,s{34,34,1571490186843,1571490186843,0,0,0,0,44,0,34} 
09:03:06.894 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] New topics: [Set(media-object-test)], deleted topics: [Set()], new partition replica assignment [Map(media-object-test-1 -> Vector(0), media-object-test-0 -> Vector(0))]
09:03:06.900 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] New partition creation callback for media-object-test-1,media-object-test-0
09:03:07.008 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x44 zxid:0x23 txntype:1 reqpath:n/a
09:03:07.008 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x44 zxid:0x23 txntype:1 reqpath:n/a
09:03:07.009 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/topics/media-object-test/partitions serverPath:/brokers/topics/media-object-test/partitions finished:false header:: 68,1  replyHeader:: 68,35,0  request:: '/brokers/topics/media-object-test/partitions,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/media-object-test/partitions 
09:03:07.015 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x45 zxid:0x24 txntype:1 reqpath:n/a
09:03:07.016 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x45 zxid:0x24 txntype:1 reqpath:n/a
09:03:07.016 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x46 zxid:0x25 txntype:1 reqpath:n/a
09:03:07.016 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x46 zxid:0x25 txntype:1 reqpath:n/a
09:03:07.016 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/topics/media-object-test/partitions/1 serverPath:/brokers/topics/media-object-test/partitions/1 finished:false header:: 69,1  replyHeader:: 69,36,0  request:: '/brokers/topics/media-object-test/partitions/1,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/media-object-test/partitions/1 
09:03:07.016 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/topics/media-object-test/partitions/0 serverPath:/brokers/topics/media-object-test/partitions/0 finished:false header:: 70,1  replyHeader:: 70,37,0  request:: '/brokers/topics/media-object-test/partitions/0,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/media-object-test/partitions/0 
09:03:07.039 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x47 zxid:0x26 txntype:1 reqpath:n/a
09:03:07.040 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x47 zxid:0x26 txntype:1 reqpath:n/a
09:03:07.040 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:create cxid:0x48 zxid:0x27 txntype:1 reqpath:n/a
09:03:07.041 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:create cxid:0x48 zxid:0x27 txntype:1 reqpath:n/a
09:03:07.041 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/topics/media-object-test/partitions/1/state serverPath:/brokers/topics/media-object-test/partitions/1/state finished:false header:: 71,1  replyHeader:: 71,38,0  request:: '/brokers/topics/media-object-test/partitions/1/state,#7b22636f6e74726f6c6c65725f65706f6368223a312c226c6561646572223a302c2276657273696f6e223a312c226c65616465725f65706f6368223a302c22697372223a5b305d7d,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/media-object-test/partitions/1/state 
09:03:07.042 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/brokers/topics/media-object-test/partitions/0/state serverPath:/brokers/topics/media-object-test/partitions/0/state finished:false header:: 72,1  replyHeader:: 72,39,0  request:: '/brokers/topics/media-object-test/partitions/0/state,#7b22636f6e74726f6c6c65725f65706f6368223a312c226c6561646572223a302c2276657273696f6e223a312c226c65616465725f65706f6368223a302c22697372223a5b305d7d,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/media-object-test/partitions/0/state 
09:03:07.096 [kafka-request-handler-5] INFO kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions media-object-test-0,media-object-test-1
09:03:07.103 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getData cxid:0x49 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/media-object-test
09:03:07.103 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getData cxid:0x49 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/media-object-test
09:03:07.103 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/topics/media-object-test serverPath:/config/topics/media-object-test finished:false header:: 73,4  replyHeader:: 73,39,0  request:: '/config/topics/media-object-test,F  response:: #7b2276657273696f6e223a312c22636f6e666967223a7b7d7d,s{33,33,1571490186818,1571490186818,0,0,0,0,25,0,33} 
09:03:07.157 [kafka-request-handler-5] DEBUG kafka.log.OffsetIndex - Loaded index file /tmp/kafka-5871668507220914040/media-object-test-0/00000000000000000000.index with maxEntries = 1310720, maxIndexSize = 10485760, entries = 0, lastOffset = 0, file position = 0
09:03:07.167 [kafka-request-handler-5] INFO kafka.log.Log - [Log partition=media-object-test-0, dir=/tmp/kafka-5871668507220914040] Loading producer state till offset 0 with message format version 2
09:03:07.178 [kafka-request-handler-5] INFO kafka.log.Log - [Log partition=media-object-test-0, dir=/tmp/kafka-5871668507220914040] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms
09:03:07.181 [kafka-request-handler-5] DEBUG kafka.utils.KafkaScheduler - Scheduling task PeriodicProducerExpirationCheck with initial delay 600000 ms and period 600000 ms.
09:03:07.182 [kafka-request-handler-5] INFO kafka.log.LogManager - Created log for partition media-object-test-0 in /tmp/kafka-5871668507220914040 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
09:03:07.184 [kafka-request-handler-5] INFO kafka.cluster.Partition - [Partition media-object-test-0 broker=0] No checkpointed highwatermark is found for partition media-object-test-0
09:03:07.188 [kafka-request-handler-5] INFO kafka.cluster.Replica - Replica loaded for partition media-object-test-0 with initial high watermark 0
09:03:07.194 [kafka-request-handler-5] INFO kafka.cluster.Partition - [Partition media-object-test-0 broker=0] media-object-test-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
09:03:07.200 [kafka-request-handler-5] DEBUG kafka.server.epoch.LeaderEpochFileCache - [LeaderEpochCache media-object-test-0] Appended new epoch entry EpochEntry(epoch=0, startOffset=0). Cache now contains 1 entries.
09:03:07.219 [kafka-request-handler-5] DEBUG kafka.cluster.Partition - [Partition media-object-test-0 broker=0] Skipping update high watermark since new hw (offset=0 segment=[0:0]) is not larger than old hw (offset=0 segment=[0:0]). All current LEOs are Set(replica 0: (offset=0 segment=[0:0]))
09:03:07.221 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x100055a6a200001 type:getData cxid:0x4a zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/media-object-test
09:03:07.221 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x100055a6a200001 type:getData cxid:0x4a zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/media-object-test
09:03:07.222 [main-SendThread(localhost.localdomain:36547)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x100055a6a200001, packet:: clientPath:/config/topics/media-object-test serverPath:/config/topics/media-object-test finished:false header:: 74,4  replyHeader:: 74,39,0  request:: '/config/topics/media-object-test,F  response:: #7b2276657273696f6e223a312c22636f6e666967223a7b7d7d,s{33,33,1571490186818,1571490186818,0,0,0,0,25,0,33} 
09:03:07.225 [kafka-request-handler-5] DEBUG kafka.log.OffsetIndex - Loaded index file /tmp/kafka-5871668507220914040/media-object-test-1/00000000000000000000.index with maxEntries = 1310720, maxIndexSize = 10485760, entries = 0, lastOffset = 0, file position = 0
09:03:07.225 [kafka-request-handler-5] INFO kafka.log.Log - [Log partition=media-object-test-1, dir=/tmp/kafka-5871668507220914040] Loading producer state till offset 0 with message format version 2
09:03:07.225 [kafka-request-handler-5] INFO kafka.log.Log - [Log partition=media-object-test-1, dir=/tmp/kafka-5871668507220914040] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
09:03:07.226 [kafka-request-handler-5] DEBUG kafka.utils.KafkaScheduler - Scheduling task PeriodicProducerExpirationCheck with initial delay 600000 ms and period 600000 ms.
09:03:07.226 [kafka-request-handler-5] INFO kafka.log.LogManager - Created log for partition media-object-test-1 in /tmp/kafka-5871668507220914040 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
09:03:07.226 [kafka-request-handler-5] INFO kafka.cluster.Partition - [Partition media-object-test-1 broker=0] No checkpointed highwatermark is found for partition media-object-test-1
09:03:07.226 [kafka-request-handler-5] INFO kafka.cluster.Replica - Replica loaded for partition media-object-test-1 with initial high watermark 0
09:03:07.226 [kafka-request-handler-5] INFO kafka.cluster.Partition - [Partition media-object-test-1 broker=0] media-object-test-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
09:03:07.226 [kafka-request-handler-5] DEBUG kafka.server.epoch.LeaderEpochFileCache - [LeaderEpochCache media-object-test-1] Appended new epoch entry EpochEntry(epoch=0, startOffset=0). Cache now contains 1 entries.
09:03:07.229 [kafka-request-handler-5] DEBUG kafka.cluster.Partition - [Partition media-object-test-1 broker=0] Skipping update high watermark since new hw (offset=0 segment=[0:0]) is not larger than old hw (offset=0 segment=[0:0]). All current LEOs are Set(replica 0: (offset=0 segment=[0:0]))
09:03:07.233 [kafka-request-handler-5] DEBUG kafka.utils.KafkaScheduler - Scheduling task highwatermark-checkpoint with initial delay 0 ms and period 9223372036854775807 ms.
09:03:07.245 [kafka-request-handler-5] INFO kafka.server.ReplicaAlterLogDirsManager - [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
09:03:07.250 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=LEADER_AND_ISR, apiVersion=1, clientId=0, correlationId=1) -- {controller_id=0,controller_epoch=1,partition_states=[{topic=media-object-test,partition=0,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],is_new=true},{topic=media-object-test,partition=1,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],is_new=true}],live_leaders=[{id=0,host=localhost,port=39851}]},response:{error_code=0,partitions=[{topic=media-object-test,partition=1,error_code=0},{topic=media-object-test,partition=0,error_code=0}]} from connection 127.0.0.1:39851-127.0.0.1:38158-0;totalTime:181.601,requestQueueTime:0.274,localTime:180.852,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.326,sendTime:0.353,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:03:07.272 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=CREATE_TOPICS, apiVersion=3, clientId=adminclient-1, correlationId=3) -- {create_topic_requests=[{topic=media-object-test,num_partitions=2,replication_factor=1,replica_assignment=[],config_entries=[]}],timeout=119906,validate_only=false},response:{throttle_time_ms=0,topic_errors=[{topic=media-object-test,error_code=0,error_message=null}]} from connection 127.0.0.1:39851-127.0.0.1:38162-0;totalTime:500.188,requestQueueTime:0.208,localTime:193.234,remoteTime:304.639,throttleTime:1.415,responseQueueTime:0.299,sendTime:0.391,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:03:07.278 [kafka-request-handler-4] DEBUG kafka.server.AdminManager - [Admin Manager on Broker 0]: Request key media-object-test unblocked 1 topic requests.
09:03:07.279 [main] DEBUG org.apache.kafka.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Initiating close operation.
09:03:07.279 [main] DEBUG org.apache.kafka.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Waiting for the I/O thread to exit. Hard shutdown in 30000 ms.
09:03:07.281 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=UPDATE_METADATA, apiVersion=4, clientId=0, correlationId=2) -- {controller_id=0,controller_epoch=1,partition_states=[{topic=media-object-test,partition=0,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],offline_replicas=[]},{topic=media-object-test,partition=1,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],offline_replicas=[]}],live_brokers=[{id=0,end_points=[{port=39851,host=localhost,listener_name=PLAINTEXT,security_protocol_type=0}],rack=null}]},response:{error_code=0} from connection 127.0.0.1:39851-127.0.0.1:38158-0;totalTime:24.2,requestQueueTime:0.407,localTime:23.32,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.146,sendTime:0.325,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:03:07.286 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
09:03:07.287 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
09:03:07.287 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name successful-authentication:
09:03:07.288 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name failed-authentication:
09:03:07.289 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
09:03:07.291 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG org.apache.kafka.common.network.Selector - [SocketServer brokerId=0] Connection with /127.0.0.1 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:96)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:335)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:296)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:562)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:498)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:427)
	at kafka.network.Processor.poll(SocketServer.scala:679)
	at kafka.network.Processor.run(SocketServer.scala:584)
	at java.base/java.lang.Thread.run(Thread.java:834)
09:03:07.292 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG org.apache.kafka.common.network.Selector - [SocketServer brokerId=0] Connection with /127.0.0.1 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:96)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:335)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:296)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:562)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:498)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:427)
	at kafka.network.Processor.poll(SocketServer.scala:679)
	at kafka.network.Processor.run(SocketServer.scala:584)
	at java.base/java.lang.Thread.run(Thread.java:834)
09:03:07.293 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
09:03:07.294 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
09:03:07.294 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
09:03:07.294 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
09:03:07.296 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
09:03:07.296 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
09:03:07.297 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
09:03:07.298 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-0.bytes-sent
09:03:07.299 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-0.bytes-received
09:03:07.299 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-0.latency
09:03:07.300 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Exiting AdminClientRunnable thread.
09:03:07.300 [main] DEBUG org.apache.kafka.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Kafka admin client closed.
09:03:07.310 [main] DEBUG org.springframework.test.context.support.AbstractDirtiesContextTestExecutionListener - Before test class: context [DefaultTestContext@2f9a4401 testClass = MediaTest, testInstance = [null], testMethod = [null], testException = [null], mergedContextConfiguration = [WebMergedContextConfiguration@22c75c01 testClass = MediaTest, locations = '{}', classes = '{class com.shoreviewanalytics.OssKafkaCassandraSpringApplication}', contextInitializerClasses = '[]', activeProfiles = '{}', propertySourceLocations = '{}', propertySourceProperties = '{org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true}', contextCustomizers = set[org.springframework.boot.test.context.filter.ExcludeFilterContextCustomizer@776b83cc, org.springframework.boot.test.json.DuplicateJsonObjectContextCustomizerFactory$DuplicateJsonObjectContextCustomizer@1bb266b3, org.springframework.boot.test.mock.mockito.MockitoContextCustomizer@0, org.springframework.boot.test.web.client.TestRestTemplateContextCustomizer@4cc8eb05, org.springframework.boot.test.autoconfigure.properties.PropertyMappingContextCustomizer@0, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverContextCustomizerFactory$Customizer@1eb5174b], resourceBasePath = 'src/main/webapp', contextLoader = 'org.springframework.boot.test.context.SpringBootContextLoader', parent = [null]], attributes = map['org.springframework.test.context.web.ServletTestExecutionListener.activateListener' -> true]], class annotated with @DirtiesContext [true] with mode [AFTER_CLASS].
09:03:07.311 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved @ProfileValueSourceConfiguration [null] for test class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest]
09:03:07.312 [main] DEBUG org.springframework.test.annotation.ProfileValueUtils - Retrieved ProfileValueSource type [class org.springframework.test.annotation.SystemProfileValueSource] for class [com.shoreviewanalytics.osskafkacassandraspring.tests.MediaTest]
09:03:07.363 [main] DEBUG org.springframework.test.context.support.TestPropertySourceUtils - Adding inlined properties to environment: {spring.jmx.enabled=false, org.springframework.boot.test.context.SpringBootTestContextBootstrapper=true, server.port=-1}

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::        (v2.1.9.RELEASE)

2019-10-19 09:03:08.573  INFO 14621 --- [           main] c.s.o.tests.MediaTest                    : Starting MediaTest on bobber with PID 14621 (started by one in /media/sf_PNY480/javacode/oss-kafka-cassandra-spring)
2019-10-19 09:03:08.577  INFO 14621 --- [           main] c.s.o.tests.MediaTest                    : No active profile set, falling back to default profiles: default
2019-10-19 09:03:12.910  INFO 14621 --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$4b4ca0bd] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-10-19 09:03:14.561  INFO 14621 --- [           main] c.d.o.d.i.core.DefaultMavenCoordinates   : DataStax Java driver for Apache Cassandra(R) (com.datastax.oss:java-driver-core) version 4.2.1
2019-10-19 09:03:15.360  INFO 14621 --- [     s0-admin-0] c.d.oss.driver.internal.core.time.Clock  : Using native clock for microsecond precision
2019-10-19 09:03:19.106  INFO 14621 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-10-19 09:03:19.713  INFO 14621 --- [           main] com.datastax.driver.core                 : DataStax Java driver 3.6.0 for Apache Cassandra
2019-10-19 09:03:19.738  INFO 14621 --- [           main] c.d.driver.core.GuavaCompatibility       : Detected Guava >= 19 in the classpath, using modern compatibility layer
2019-10-19 09:03:19.828  INFO 14621 --- [           main] com.datastax.driver.core.ClockFactory    : Using native clock to generate timestamps.
2019-10-19 09:03:20.355  INFO 14621 --- [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:39851]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2019-10-19 09:03:20.360  INFO 14621 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-10-19 09:03:20.360  INFO 14621 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-10-19 09:03:20.399  INFO 14621 --- [0 cport:36547):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x100055a6a200001 type:setData cxid:0x4c zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics/media Error:KeeperErrorCode = NoNode for /config/topics/media
2019-10-19 09:03:20.406  INFO 14621 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Topic creation Map(media-2 -> ArrayBuffer(0), media-1 -> ArrayBuffer(0), media-0 -> ArrayBuffer(0))
2019-10-19 09:03:20.414  INFO 14621 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(media)], deleted topics: [Set()], new partition replica assignment [Map(media-2 -> Vector(0), media-1 -> Vector(0), media-0 -> Vector(0))]
2019-10-19 09:03:20.415  INFO 14621 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for media-2,media-1,media-0
2019-10-19 09:03:20.430  INFO 14621 --- [quest-handler-3] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions media-0,media-1,media-2
2019-10-19 09:03:20.433  INFO 14621 --- [quest-handler-3] kafka.log.Log                            : [Log partition=media-0, dir=/tmp/kafka-5871668507220914040] Loading producer state till offset 0 with message format version 2
2019-10-19 09:03:20.434  INFO 14621 --- [quest-handler-3] kafka.log.Log                            : [Log partition=media-0, dir=/tmp/kafka-5871668507220914040] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2019-10-19 09:03:20.435  INFO 14621 --- [quest-handler-3] kafka.log.LogManager                     : Created log for partition media-0 in /tmp/kafka-5871668507220914040 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-10-19 09:03:20.435  INFO 14621 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition media-0 broker=0] No checkpointed highwatermark is found for partition media-0
2019-10-19 09:03:20.435  INFO 14621 --- [quest-handler-3] kafka.cluster.Replica                    : Replica loaded for partition media-0 with initial high watermark 0
2019-10-19 09:03:20.435  INFO 14621 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition media-0 broker=0] media-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-10-19 09:03:20.441  INFO 14621 --- [quest-handler-3] kafka.log.Log                            : [Log partition=media-1, dir=/tmp/kafka-5871668507220914040] Loading producer state till offset 0 with message format version 2
2019-10-19 09:03:20.441  INFO 14621 --- [quest-handler-3] kafka.log.Log                            : [Log partition=media-1, dir=/tmp/kafka-5871668507220914040] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2019-10-19 09:03:20.442  INFO 14621 --- [quest-handler-3] kafka.log.LogManager                     : Created log for partition media-1 in /tmp/kafka-5871668507220914040 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-10-19 09:03:20.442  INFO 14621 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition media-1 broker=0] No checkpointed highwatermark is found for partition media-1
2019-10-19 09:03:20.443  INFO 14621 --- [quest-handler-3] kafka.cluster.Replica                    : Replica loaded for partition media-1 with initial high watermark 0
2019-10-19 09:03:20.443  INFO 14621 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition media-1 broker=0] media-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-10-19 09:03:20.451  INFO 14621 --- [quest-handler-3] kafka.log.Log                            : [Log partition=media-2, dir=/tmp/kafka-5871668507220914040] Loading producer state till offset 0 with message format version 2
2019-10-19 09:03:20.452  INFO 14621 --- [quest-handler-3] kafka.log.Log                            : [Log partition=media-2, dir=/tmp/kafka-5871668507220914040] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2019-10-19 09:03:20.453  INFO 14621 --- [quest-handler-3] kafka.log.LogManager                     : Created log for partition media-2 in /tmp/kafka-5871668507220914040 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-10-19 09:03:20.453  INFO 14621 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition media-2 broker=0] No checkpointed highwatermark is found for partition media-2
2019-10-19 09:03:20.453  INFO 14621 --- [quest-handler-3] kafka.cluster.Replica                    : Replica loaded for partition media-2 with initial high watermark 0
2019-10-19 09:03:20.453  INFO 14621 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition media-2 broker=0] media-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-10-19 09:03:20.456  INFO 14621 --- [quest-handler-3] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
2019-10-19 09:03:20.480  INFO 14621 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:39851]
	check.crcs = true
	client.id = media-json
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = tpd-loggers
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2019-10-19 09:03:20.564  INFO 14621 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-10-19 09:03:20.564  INFO 14621 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-10-19 09:03:20.577  INFO 14621 --- [           main] org.apache.kafka.clients.Metadata        : Cluster ID: 54B6LOMbQ7qjyFjWAmZ0qw
2019-10-19 09:03:20.613  INFO 14621 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:39851]
	check.crcs = true
	client.id = media-json-0
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = tpd-loggers
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2019-10-19 09:03:20.618  INFO 14621 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-10-19 09:03:20.618  INFO 14621 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-10-19 09:03:20.625  INFO 14621 --- [           main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2019-10-19 09:03:20.653  INFO 14621 --- [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : Cluster ID: 54B6LOMbQ7qjyFjWAmZ0qw
2019-10-19 09:03:20.671  INFO 14621 --- [0 cport:36547):] o.a.z.server.PrepRequestProcessor        : Got user-level KeeperException when processing sessionid:0x100055a6a200001 type:setData cxid:0x5f zxid:0x32 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2019-10-19 09:03:20.676  INFO 14621 --- [quest-handler-0] kafka.zk.AdminZkClient                   : Topic creation Map(__consumer_offsets-4 -> ArrayBuffer(0), __consumer_offsets-3 -> ArrayBuffer(0), __consumer_offsets-2 -> ArrayBuffer(0), __consumer_offsets-0 -> ArrayBuffer(0), __consumer_offsets-1 -> ArrayBuffer(0))
2019-10-19 09:03:20.680  INFO 14621 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-4 -> Vector(0), __consumer_offsets-3 -> Vector(0), __consumer_offsets-2 -> Vector(0), __consumer_offsets-0 -> Vector(0), __consumer_offsets-1 -> Vector(0))]
2019-10-19 09:03:20.680  INFO 14621 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2019-10-19 09:03:20.681  INFO 14621 --- [quest-handler-0] kafka.server.KafkaApis                   : [KafkaApi-0] Auto creation of topic __consumer_offsets with 5 partitions and replication factor 1 is successful
2019-10-19 09:03:20.694  INFO 14621 --- [           main] c.s.o.tests.MediaTest                    : Started MediaTest in 13.313 seconds (JVM running for 21.049)
2019-10-19 09:03:20.720  INFO 14621 --- [quest-handler-3] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
2019-10-19 09:03:20.727  INFO 14621 --- [quest-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=/tmp/kafka-5871668507220914040] Loading producer state till offset 0 with message format version 2
2019-10-19 09:03:20.728  INFO 14621 --- [quest-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-0, dir=/tmp/kafka-5871668507220914040] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
2019-10-19 09:03:20.729  INFO 14621 --- [quest-handler-3] kafka.log.LogManager                     : Created log for partition __consumer_offsets-0 in /tmp/kafka-5871668507220914040 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-10-19 09:03:20.729  INFO 14621 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
2019-10-19 09:03:20.730  INFO 14621 --- [quest-handler-3] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
2019-10-19 09:03:20.730  INFO 14621 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-10-19 09:03:20.737  INFO 14621 --- [quest-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=/tmp/kafka-5871668507220914040] Loading producer state till offset 0 with message format version 2
2019-10-19 09:03:20.737  INFO 14621 --- [quest-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-4, dir=/tmp/kafka-5871668507220914040] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2019-10-19 09:03:20.738  INFO 14621 --- [quest-handler-3] kafka.log.LogManager                     : Created log for partition __consumer_offsets-4 in /tmp/kafka-5871668507220914040 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-10-19 09:03:20.739  INFO 14621 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
2019-10-19 09:03:20.739  INFO 14621 --- [quest-handler-3] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
2019-10-19 09:03:20.739  INFO 14621 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-10-19 09:03:20.761  INFO 14621 --- [quest-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=/tmp/kafka-5871668507220914040] Loading producer state till offset 0 with message format version 2
2019-10-19 09:03:20.764  INFO 14621 --- [quest-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-1, dir=/tmp/kafka-5871668507220914040] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms
2019-10-19 09:03:20.766  INFO 14621 --- [quest-handler-3] kafka.log.LogManager                     : Created log for partition __consumer_offsets-1 in /tmp/kafka-5871668507220914040 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-10-19 09:03:20.768  INFO 14621 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
2019-10-19 09:03:20.768  INFO 14621 --- [quest-handler-3] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
2019-10-19 09:03:20.768  INFO 14621 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-10-19 09:03:20.777  INFO 14621 --- [quest-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=/tmp/kafka-5871668507220914040] Loading producer state till offset 0 with message format version 2
2019-10-19 09:03:20.778  INFO 14621 --- [quest-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-2, dir=/tmp/kafka-5871668507220914040] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms
2019-10-19 09:03:20.790  INFO 14621 --- [quest-handler-3] kafka.log.LogManager                     : Created log for partition __consumer_offsets-2 in /tmp/kafka-5871668507220914040 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-10-19 09:03:20.791  INFO 14621 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
2019-10-19 09:03:20.791  INFO 14621 --- [quest-handler-3] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
2019-10-19 09:03:20.792  INFO 14621 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-10-19 09:03:20.800  INFO 14621 --- [quest-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=/tmp/kafka-5871668507220914040] Loading producer state till offset 0 with message format version 2
2019-10-19 09:03:20.800  INFO 14621 --- [quest-handler-3] kafka.log.Log                            : [Log partition=__consumer_offsets-3, dir=/tmp/kafka-5871668507220914040] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms
2019-10-19 09:03:20.801  INFO 14621 --- [quest-handler-3] kafka.log.LogManager                     : Created log for partition __consumer_offsets-3 in /tmp/kafka-5871668507220914040 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, segment.ms -> 604800000, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2019-10-19 09:03:20.802  INFO 14621 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
2019-10-19 09:03:20.802  INFO 14621 --- [quest-handler-3] kafka.cluster.Replica                    : Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
2019-10-19 09:03:20.802  INFO 14621 --- [quest-handler-3] kafka.cluster.Partition                  : [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
2019-10-19 09:03:20.806  INFO 14621 --- [quest-handler-3] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
2019-10-19 09:03:20.815  INFO 14621 --- [quest-handler-3] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3
2019-10-19 09:03:20.817  INFO 14621 --- [quest-handler-3] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2
2019-10-19 09:03:20.817  INFO 14621 --- [quest-handler-3] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1
2019-10-19 09:03:20.818  INFO 14621 --- [quest-handler-3] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4
2019-10-19 09:03:20.818  INFO 14621 --- [quest-handler-3] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0
2019-10-19 09:03:20.845  INFO 14621 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 27 milliseconds.
2019-10-19 09:03:20.848  INFO 14621 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 1 milliseconds.
2019-10-19 09:03:20.848  INFO 14621 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
2019-10-19 09:03:20.849  INFO 14621 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
2019-10-19 09:03:20.849  INFO 14621 --- [adata-manager-0] k.c.group.GroupMetadataManager           : [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
2019-10-19 09:03:20.863  INFO 14621 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=media-json-0, groupId=tpd-loggers] Discovered group coordinator localhost:39851 (id: 2147483647 rack: null)
2019-10-19 09:03:20.875  INFO 14621 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=media-json-0, groupId=tpd-loggers] Revoking previously assigned partitions []
2019-10-19 09:03:20.875  INFO 14621 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions revoked: []
2019-10-19 09:03:20.875  INFO 14621 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=media-json-0, groupId=tpd-loggers] (Re-)joining group
2019-10-19 09:03:20.912  INFO 14621 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group tpd-loggers with old generation 0 (__consumer_offsets-0)
2019-10-19 09:03:20.936  INFO 14621 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group tpd-loggers generation 1 (__consumer_offsets-0)
2019-10-19 09:03:20.964  INFO 14621 --- [quest-handler-6] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader for group tpd-loggers for generation 1
2019-10-19 09:03:21.124  INFO 14621 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=media-json-0, groupId=tpd-loggers] Successfully joined group with generation 1
2019-10-19 09:03:21.132  INFO 14621 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=media-json-0, groupId=tpd-loggers] Setting newly assigned partitions [media-0, media-1, media-2]
2019-10-19 09:03:21.172  INFO 14621 --- [ntainer#0-0-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=media-json-0, groupId=tpd-loggers] Resetting offset for partition media-0 to offset 0.
2019-10-19 09:03:21.173  INFO 14621 --- [ntainer#0-0-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=media-json-0, groupId=tpd-loggers] Resetting offset for partition media-1 to offset 0.
2019-10-19 09:03:21.174  INFO 14621 --- [ntainer#0-0-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=media-json-0, groupId=tpd-loggers] Resetting offset for partition media-2 to offset 0.
2019-10-19 09:03:21.176  INFO 14621 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions assigned: [media-0, media-1, media-2]
2019-10-19 09:03:21.768  INFO 14621 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 10
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:39851]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sender
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 60000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-10-19 09:03:21.777  INFO 14621 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-10-19 09:03:21.777  INFO 14621 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-10-19 09:03:21.793  INFO 14621 --- [           main] org.apache.kafka.clients.Metadata        : Cluster ID: 54B6LOMbQ7qjyFjWAmZ0qw
2019-10-19 09:03:21.801  INFO 14621 --- [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 10
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:39851]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = sender
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 60000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2019-10-19 09:03:21.807  INFO 14621 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-10-19 09:03:21.808  INFO 14621 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-10-19 09:03:21.808  INFO 14621 --- [           main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2019-10-19 09:03:21.831  INFO 14621 --- [           -C-1] org.apache.kafka.clients.Metadata        : Cluster ID: 54B6LOMbQ7qjyFjWAmZ0qw
2019-10-19 09:03:21.832  INFO 14621 --- [           -C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=sender] Discovered group coordinator localhost:39851 (id: 2147483647 rack: null)
2019-10-19 09:03:21.839  INFO 14621 --- [           -C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=sender] Revoking previously assigned partitions []
2019-10-19 09:03:21.839  INFO 14621 --- [           -C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions revoked: []
2019-10-19 09:03:21.839  INFO 14621 --- [           -C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=sender] (Re-)joining group
2019-10-19 09:03:21.844  INFO 14621 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group sender with old generation 0 (__consumer_offsets-0)
2019-10-19 09:03:21.846  INFO 14621 --- [cutor-Rebalance] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Stabilized group sender generation 1 (__consumer_offsets-0)
2019-10-19 09:03:21.851  INFO 14621 --- [quest-handler-7] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Assignment received from leader for group sender for generation 1
2019-10-19 09:03:21.854  INFO 14621 --- [           -C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=sender] Successfully joined group with generation 1
2019-10-19 09:03:21.859  INFO 14621 --- [           -C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=sender] Setting newly assigned partitions [media-object-test-0, media-object-test-1]
2019-10-19 09:03:21.871  INFO 14621 --- [           -C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-2, groupId=sender] Resetting offset for partition media-object-test-0 to offset 0.
2019-10-19 09:03:21.873  INFO 14621 --- [           -C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-2, groupId=sender] Resetting offset for partition media-object-test-1 to offset 0.
2019-10-19 09:03:21.921  INFO 14621 --- [           -C-1] o.s.k.l.KafkaMessageListenerContainer    : partitions assigned: [media-object-test-0, media-object-test-1]
The object mapper value is {"title":"test title","added_year":"2019","added_date":"05-11-2019","description":"test description","userid":"12345","videoid":"12345"}
2019-10-19 09:03:22.086  INFO 14621 --- [           main] c.s.kafka.producer.Sender                : sending data='{"title":"test title","added_year":"2019","added_date":"05-11-2019","description":"test description","userid":"12345","videoid":"12345"}' to topic='media-object-test'
2019-10-19 09:03:22.096  INFO 14621 --- [           main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:39851]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2019-10-19 09:03:22.127  INFO 14621 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-10-19 09:03:22.128  INFO 14621 --- [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-10-19 09:03:22.138  INFO 14621 --- [ad | producer-1] org.apache.kafka.clients.Metadata        : Cluster ID: 54B6LOMbQ7qjyFjWAmZ0qw
2019-10-19 09:03:22.182  INFO 14621 --- [           -C-1] c.s.o.tests.SenderTest                   : test-listener received message='ConsumerRecord(topic = media-object-test, partition = 0, offset = 0, CreateTime = 1571490202142, serialized key size = -1, serialized value size = 136, headers = RecordHeaders(headers = [RecordHeader(key = __TypeId__, value = [99, 111, 109, 46, 102, 97, 115, 116, 101, 114, 120, 109, 108, 46, 106, 97, 99, 107, 115, 111, 110, 46, 100, 97, 116, 97, 98, 105, 110, 100, 46, 110, 111, 100, 101, 46, 79, 98, 106, 101, 99, 116, 78, 111, 100, 101])], isReadOnly = false), key = null, value = {"title":"test title","added_year":"2019","added_date":"05-11-2019","description":"test description","userid":"12345","videoid":"12345"})'
2019-10-19 09:03:22.198  INFO 14621 --- [           -C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2019-10-19 09:03:22.204  INFO 14621 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group sender with old generation 1 (__consumer_offsets-0)
2019-10-19 09:03:22.208  INFO 14621 --- [quest-handler-0] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group sender with generation 2 is now empty (__consumer_offsets-0)
2019-10-19 09:03:22.219  INFO 14621 --- [           -C-1] essageListenerContainer$ListenerConsumer : Consumer stopped
2019-10-19 09:03:22.242  INFO 14621 --- [ntainer#0-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2019-10-19 09:03:22.249  INFO 14621 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Preparing to rebalance group tpd-loggers with old generation 1 (__consumer_offsets-0)
2019-10-19 09:03:22.250  INFO 14621 --- [quest-handler-3] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Group tpd-loggers with generation 2 is now empty (__consumer_offsets-0)
2019-10-19 09:03:22.253  INFO 14621 --- [ntainer#0-0-C-1] essageListenerContainer$ListenerConsumer : Consumer stopped
2019-10-19 09:03:22.269  INFO 14621 --- [           main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2019-10-19 09:03:22.272  INFO 14621 --- [           main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2019-10-19 09:03:22.280  INFO 14621 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] shutting down
2019-10-19 09:03:22.282  INFO 14621 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] Starting controlled shutdown
2019-10-19 09:03:22.297  INFO 14621 --- [er-event-thread] kafka.controller.KafkaController         : [Controller id=0] Shutting down broker 0
2019-10-19 09:03:22.312  INFO 14621 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] Controlled shutdown succeeded
2019-10-19 09:03:22.319  INFO 14621 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutting down
2019-10-19 09:03:22.320  INFO 14621 --- [-process-thread] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Stopped
2019-10-19 09:03:22.321  INFO 14621 --- [           main] icationListener$ChangeEventProcessThread : [/config/changes-event-process-thread]: Shutdown completed
2019-10-19 09:03:22.323  INFO 14621 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=0] Stopping socket server request processors
2019-10-19 09:03:22.352  INFO 14621 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=0] Stopped socket server request processors
2019-10-19 09:03:22.354  INFO 14621 --- [           main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 0], shutting down
2019-10-19 09:03:22.361  INFO 14621 --- [           main] kafka.server.KafkaRequestHandlerPool     : [Kafka Request Handler on Broker 0], shut down completely
2019-10-19 09:03:22.369  INFO 14621 --- [           main] kafka.server.KafkaApis                   : [KafkaApi-0] Shutdown complete.
2019-10-19 09:03:22.372  INFO 14621 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutting down
2019-10-19 09:03:22.528  INFO 14621 --- [nReaper-0-topic] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Stopped
2019-10-19 09:03:22.528  INFO 14621 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-topic]: Shutdown completed
2019-10-19 09:03:22.534  INFO 14621 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutting down.
2019-10-19 09:03:22.536  INFO 14621 --- [           main] k.c.transaction.ProducerIdManager        : [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
2019-10-19 09:03:22.537  INFO 14621 --- [           main] k.c.transaction.TransactionStateManager  : [Transaction State Manager 0]: Shutdown complete
2019-10-19 09:03:22.537  INFO 14621 --- [           main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Shutting down
2019-10-19 09:03:22.540  INFO 14621 --- [rSenderThread-0] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Stopped
2019-10-19 09:03:22.540  INFO 14621 --- [           main] k.c.t.TransactionMarkerChannelManager    : [Transaction Marker Channel Manager 0]: Shutdown completed
2019-10-19 09:03:22.542  INFO 14621 --- [           main] k.c.transaction.TransactionCoordinator   : [TransactionCoordinator id=0] Shutdown complete.
2019-10-19 09:03:22.543  INFO 14621 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutting down.
2019-10-19 09:03:22.544  INFO 14621 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutting down
2019-10-19 09:03:22.728  INFO 14621 --- [per-0-Heartbeat] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Stopped
2019-10-19 09:03:22.728  INFO 14621 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Heartbeat]: Shutdown completed
2019-10-19 09:03:22.728  INFO 14621 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutting down
2019-10-19 09:03:22.852  INFO 14621 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Shutdown completed
2019-10-19 09:03:22.852  INFO 14621 --- [per-0-Rebalance] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Rebalance]: Stopped
2019-10-19 09:03:22.856  INFO 14621 --- [           main] k.coordinator.group.GroupCoordinator     : [GroupCoordinator 0]: Shutdown complete.
2019-10-19 09:03:22.860  INFO 14621 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shutting down
2019-10-19 09:03:22.862  INFO 14621 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutting down
2019-10-19 09:03:22.863  INFO 14621 --- [           main] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Shutdown completed
2019-10-19 09:03:22.863  INFO 14621 --- [rFailureHandler] k.s.ReplicaManager$LogDirFailureHandler  : [LogDirFailureHandler]: Stopped
2019-10-19 09:03:22.864  INFO 14621 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutting down
2019-10-19 09:03:22.869  INFO 14621 --- [           main] kafka.server.ReplicaFetcherManager       : [ReplicaFetcherManager on broker 0] shutdown completed
2019-10-19 09:03:22.870  INFO 14621 --- [           main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] shutting down
2019-10-19 09:03:22.872  INFO 14621 --- [           main] kafka.server.ReplicaAlterLogDirsManager  : [ReplicaAlterLogDirsManager on broker 0] shutdown completed
2019-10-19 09:03:22.872  INFO 14621 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutting down
2019-10-19 09:03:22.876  INFO 14621 --- [nReaper-0-Fetch] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Stopped
2019-10-19 09:03:22.876  INFO 14621 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Fetch]: Shutdown completed
2019-10-19 09:03:22.877  INFO 14621 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutting down
2019-10-19 09:03:22.926  INFO 14621 --- [eaper-0-Produce] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Stopped
2019-10-19 09:03:22.926  INFO 14621 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-Produce]: Shutdown completed
2019-10-19 09:03:22.926  INFO 14621 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutting down
2019-10-19 09:03:23.126  INFO 14621 --- [0-DeleteRecords] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Stopped
2019-10-19 09:03:23.126  INFO 14621 --- [           main] perationPurgatory$ExpiredOperationReaper : [ExpirationReaper-0-DeleteRecords]: Shutdown completed
2019-10-19 09:03:23.131  INFO 14621 --- [           main] kafka.server.ReplicaManager              : [ReplicaManager broker=0] Shut down completely
2019-10-19 09:03:23.133  INFO 14621 --- [           main] kafka.log.LogManager                     : Shutting down.
2019-10-19 09:03:23.137  INFO 14621 --- [           main] kafka.log.LogCleaner                     : Shutting down the log cleaner.
2019-10-19 09:03:23.138  INFO 14621 --- [           main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutting down
2019-10-19 09:03:23.139  INFO 14621 --- [leaner-thread-0] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Stopped
2019-10-19 09:03:23.139  INFO 14621 --- [           main] kafka.log.LogCleaner                     : [kafka-log-cleaner-thread-0]: Shutdown completed
2019-10-19 09:03:23.183  INFO 14621 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=media-object-test-0] Writing producer snapshot at offset 1
2019-10-19 09:03:23.188  INFO 14621 --- [pool-8-thread-1] kafka.log.ProducerStateManager           : [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 7
2019-10-19 09:03:23.218  INFO 14621 --- [           main] kafka.log.LogManager                     : Shutdown complete.
2019-10-19 09:03:23.220  INFO 14621 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutting down
2019-10-19 09:03:23.220  INFO 14621 --- [er-event-thread] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Stopped
2019-10-19 09:03:23.221  INFO 14621 --- [           main] rollerEventManager$ControllerEventThread : [ControllerEventThread controllerId=0] Shutdown completed
2019-10-19 09:03:23.228  INFO 14621 --- [           main] kafka.controller.PartitionStateMachine   : [PartitionStateMachine controllerId=0] Stopped partition state machine
2019-10-19 09:03:23.231  INFO 14621 --- [           main] kafka.controller.ReplicaStateMachine     : [ReplicaStateMachine controllerId=0] Stopped replica state machine
2019-10-19 09:03:23.232  INFO 14621 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutting down
2019-10-19 09:03:23.232  INFO 14621 --- [r-0-send-thread] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Stopped
2019-10-19 09:03:23.233  INFO 14621 --- [           main] kafka.controller.RequestSendThread       : [RequestSendThread controllerId=0] Shutdown completed
2019-10-19 09:03:23.235  INFO 14621 --- [           main] kafka.controller.KafkaController         : [Controller id=0] Resigned
2019-10-19 09:03:23.237  INFO 14621 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closing.
2019-10-19 09:03:23.239  INFO 14621 --- [0 cport:36547):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x100055a6a200001
2019-10-19 09:03:23.242  INFO 14621 --- [ry:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:43694 which had sessionid 0x100055a6a200001
2019-10-19 09:03:23.242  INFO 14621 --- [ain-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x100055a6a200001
2019-10-19 09:03:23.242  INFO 14621 --- [           main] org.apache.zookeeper.ZooKeeper           : Session: 0x100055a6a200001 closed
2019-10-19 09:03:23.247  INFO 14621 --- [           main] kafka.zookeeper.ZooKeeperClient          : [ZooKeeperClient] Closed.
2019-10-19 09:03:23.248  INFO 14621 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutting down
2019-10-19 09:03:23.359  INFO 14621 --- [nelReaper-Fetch] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Stopped
2019-10-19 09:03:23.359  INFO 14621 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Fetch]: Shutdown completed
2019-10-19 09:03:23.360  INFO 14621 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutting down
2019-10-19 09:03:24.359  INFO 14621 --- [lReaper-Produce] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Stopped
2019-10-19 09:03:24.360  INFO 14621 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Produce]: Shutdown completed
2019-10-19 09:03:24.360  INFO 14621 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutting down
2019-10-19 09:03:25.360  INFO 14621 --- [           main] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Shutdown completed
2019-10-19 09:03:25.360  INFO 14621 --- [lReaper-Request] lientQuotaManager$ThrottledChannelReaper : [ThrottledChannelReaper-Request]: Stopped
2019-10-19 09:03:25.364  INFO 14621 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=0] Shutting down socket server
2019-10-19 09:03:25.415  INFO 14621 --- [           main] kafka.network.SocketServer               : [SocketServer brokerId=0] Shutdown completed
2019-10-19 09:03:25.433  INFO 14621 --- [           main] kafka.server.KafkaServer                 : [KafkaServer id=0] shut down completed
2019-10-19 09:03:25.443  INFO 14621 --- [127.0.0.1:36547] org.I0Itec.zkclient.ZkEventThread        : Terminate ZkClient event thread.
2019-10-19 09:03:25.445  INFO 14621 --- [0 cport:36547):] o.a.z.server.PrepRequestProcessor        : Processed session termination for sessionid: 0x100055a6a200000
2019-10-19 09:03:25.446  INFO 14621 --- [ry:/127.0.0.1:0] o.apache.zookeeper.server.NIOServerCnxn  : Closed socket connection for client /127.0.0.1:43692 which had sessionid 0x100055a6a200000
2019-10-19 09:03:25.447  INFO 14621 --- [           main] org.apache.zookeeper.ZooKeeper           : Session: 0x100055a6a200000 closed
2019-10-19 09:03:25.447  INFO 14621 --- [ain-EventThread] org.apache.zookeeper.ClientCnxn          : EventThread shut down for session: 0x100055a6a200000
2019-10-19 09:03:25.448  INFO 14621 --- [           main] o.a.zookeeper.server.ZooKeeperServer     : shutting down
2019-10-19 09:03:25.448  INFO 14621 --- [           main] o.a.zookeeper.server.SessionTrackerImpl  : Shutting down
2019-10-19 09:03:25.449  INFO 14621 --- [           main] o.a.z.server.PrepRequestProcessor        : Shutting down
2019-10-19 09:03:25.449  INFO 14621 --- [           main] o.a.z.server.SyncRequestProcessor        : Shutting down
2019-10-19 09:03:25.449  INFO 14621 --- [0 cport:36547):] o.a.z.server.PrepRequestProcessor        : PrepRequestProcessor exited loop!
2019-10-19 09:03:25.449  INFO 14621 --- [   SyncThread:0] o.a.z.server.SyncRequestProcessor        : SyncRequestProcessor exited!
2019-10-19 09:03:25.450  INFO 14621 --- [           main] o.a.z.server.FinalRequestProcessor       : shutdown of request processor complete
2019-10-19 09:03:25.455  INFO 14621 --- [ry:/127.0.0.1:0] o.a.z.server.NIOServerCnxnFactory        : NIOServerCnxn factory exited run method
[[1;34mINFO[m] [1;32mTests run: [0;1;32m1[m, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 25.242 s - in com.shoreviewanalytics.osskafkacassandraspring.tests.[1mMediaTest[m
2019-10-19 09:03:25.495  INFO 14621 --- [ SessionTracker] o.a.zookeeper.server.SessionTrackerImpl  : SessionTrackerImpl exited loop!
[[1;34mINFO[m] 
[[1;34mINFO[m] Results:
[[1;34mINFO[m] 
[[1;34mINFO[m] [1;32mTests run: 1, Failures: 0, Errors: 0, Skipped: 0[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] [1;32mBUILD SUCCESS[m
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
[[1;34mINFO[m] Total time: 33.063 s
[[1;34mINFO[m] Finished at: 2019-10-19T09:03:25-04:00
[[1;34mINFO[m] Final Memory: 45M/154M
[[1;34mINFO[m] [1m------------------------------------------------------------------------[m
